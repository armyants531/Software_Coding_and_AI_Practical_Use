{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660a4475",
   "metadata": {},
   "source": [
    "## 남방톱날꽃게(청게)의 나이 예측 딥러닝 모델 구현 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282a42cb",
   "metadata": {},
   "source": [
    "본 소스 파일에서는 이전의 모델 1과는 다르게 과적합 예방을 위해 K겹 교차 검증 방식(K-fold Cross Validation)을 사용하였다. 과적합을 막기 위해 EarlyStopping() 함수를 이용하여 학습 자동 중단 과정을 설정한 것은 같다.   \n",
    "다중 선형 회귀 분석의 방법을 사용하여 정확도를 MAE(Mean Absolute Error)를 이용해 평가하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d6c55e",
   "metadata": {},
   "source": [
    "### 1. 필요한 라이브러리 import하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcff1ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager   # 한글 사용을 위해 import\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c90658",
   "metadata": {},
   "source": [
    "tensorflow 버전 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ff4929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b46fbbc",
   "metadata": {},
   "source": [
    "tensorboard import & version 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f80c72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorboard\n",
    "\n",
    "tensorboard.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d16c70",
   "metadata": {},
   "source": [
    "### 2. 데이터셋 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e268d3",
   "metadata": {},
   "source": [
    "상대경로를 사용하여 최종적으로 가공된 데이터셋을 가져온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e22db6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"./3_Dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6850948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e960f4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Viscera Weight</th>\n",
       "      <th>Shell Weight</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4375</td>\n",
       "      <td>1.1750</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>24.635715</td>\n",
       "      <td>5.584852</td>\n",
       "      <td>6.747181</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>5.400580</td>\n",
       "      <td>1.374951</td>\n",
       "      <td>1.559222</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0375</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>7.952035</td>\n",
       "      <td>1.601747</td>\n",
       "      <td>2.764076</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1750</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>13.480187</td>\n",
       "      <td>2.282135</td>\n",
       "      <td>5.244657</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>6.903103</td>\n",
       "      <td>1.488349</td>\n",
       "      <td>1.700970</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>1.4625</td>\n",
       "      <td>1.1375</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>24.819987</td>\n",
       "      <td>5.854172</td>\n",
       "      <td>6.378637</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848</th>\n",
       "      <td>1.5500</td>\n",
       "      <td>1.2125</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>34.458817</td>\n",
       "      <td>7.172423</td>\n",
       "      <td>9.780577</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>2.012815</td>\n",
       "      <td>0.524466</td>\n",
       "      <td>0.637864</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>1.0625</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>10.347568</td>\n",
       "      <td>2.338834</td>\n",
       "      <td>2.976698</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.6125</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>4.068153</td>\n",
       "      <td>1.346601</td>\n",
       "      <td>1.417475</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3852 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Length  Diameter  Height     Weight  Viscera Weight  Shell Weight  Age  \\\n",
       "0     1.4375    1.1750  0.4125  24.635715        5.584852      6.747181    9   \n",
       "1     0.8875    0.6500  0.2125   5.400580        1.374951      1.559222    6   \n",
       "2     1.0375    0.7750  0.2500   7.952035        1.601747      2.764076    6   \n",
       "3     1.1750    0.8875  0.2500  13.480187        2.282135      5.244657   10   \n",
       "4     0.8875    0.6625  0.2125   6.903103        1.488349      1.700970    6   \n",
       "...      ...       ...     ...        ...             ...           ...  ...   \n",
       "3847  1.4625    1.1375  0.3250  24.819987        5.854172      6.378637    8   \n",
       "3848  1.5500    1.2125  0.4375  34.458817        7.172423      9.780577   10   \n",
       "3849  0.6250    0.4625  0.1625   2.012815        0.524466      0.637864    5   \n",
       "3850  1.0625    0.7750  0.2625  10.347568        2.338834      2.976698    6   \n",
       "3851  0.7875    0.6125  0.2125   4.068153        1.346601      1.417475    8   \n",
       "\n",
       "      Sex_F  Sex_I  Sex_M  \n",
       "0         1      0      0  \n",
       "1         0      0      1  \n",
       "2         0      1      0  \n",
       "3         1      0      0  \n",
       "4         0      1      0  \n",
       "...     ...    ...    ...  \n",
       "3847      1      0      0  \n",
       "3848      1      0      0  \n",
       "3849      0      1      0  \n",
       "3850      0      1      0  \n",
       "3851      0      1      0  \n",
       "\n",
       "[3852 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c66ea07",
   "metadata": {},
   "source": [
    "### 3. 딥러닝을 위해 독립변수(x)와 종속변수(y)로 데이터 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f24d7df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#종속변수 \n",
    "df_y = df['Age'].values\n",
    "#독립변수\n",
    "df_x = df.drop(['Age'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "823de38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4375, 1.175 , 0.4125, ..., 1.    , 0.    , 0.    ],\n",
       "       [0.8875, 0.65  , 0.2125, ..., 0.    , 0.    , 1.    ],\n",
       "       [1.0375, 0.775 , 0.25  , ..., 0.    , 1.    , 0.    ],\n",
       "       ...,\n",
       "       [0.625 , 0.4625, 0.1625, ..., 0.    , 1.    , 0.    ],\n",
       "       [1.0625, 0.775 , 0.2625, ..., 0.    , 1.    , 0.    ],\n",
       "       [0.7875, 0.6125, 0.2125, ..., 0.    , 1.    , 0.    ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dce7a6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 6, 6, ..., 5, 6, 8], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe4963e",
   "metadata": {},
   "source": [
    "### 4.  K-겹 교차 검증(K-fold Cross Validation)을 사용한 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4a616f",
   "metadata": {},
   "source": [
    "sklearn에서 제공하는 StratifiedKFold 함수를 사용해 K-겹 교차 검증을 한다.  \n",
    "StratifiedKFold 함수의 옵션 중에서 n_splits 부분은 K-겹에서 K에 해당하는 값이다.  \n",
    "본 소스 코드에서는 5로 설정하여 5개의 그룹으로 데이터셋을 나누어 보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fba8f79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# seed 값 설정\n",
    "seed = 2\n",
    "\n",
    "# k 값 설정\n",
    "n_fold = 5\n",
    "skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7f5bbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedKFold(n_splits=5, random_state=2, shuffle=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6beb05",
   "metadata": {},
   "source": [
    "X(독립변수)와 Y(종속변수)의 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "811a2194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> X의 개수 :  3852\n",
      "[[1.4375 1.175  0.4125 ... 1.     0.     0.    ]\n",
      " [0.8875 0.65   0.2125 ... 0.     0.     1.    ]\n",
      " [1.0375 0.775  0.25   ... 0.     1.     0.    ]\n",
      " ...\n",
      " [0.625  0.4625 0.1625 ... 0.     1.     0.    ]\n",
      " [1.0625 0.775  0.2625 ... 0.     1.     0.    ]\n",
      " [0.7875 0.6125 0.2125 ... 0.     1.     0.    ]]\n",
      "\n",
      "-> Y의 개수 :  3852\n",
      "[9 6 6 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "print(\"-> X의 개수 : \", len(df_x))\n",
    "print(df_x)\n",
    "\n",
    "print(\"\\n-> Y의 개수 : \", len(df_y))\n",
    "print(df_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f974ea",
   "metadata": {},
   "source": [
    "학습 데이터 개수와 테스트 데이터 개수 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b4f5f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 개수 :  3852\n",
      "각 데이터셋의 개수 :  770\n",
      "학습 데이터 개수 :  3082\n",
      "테스트 데이터 개수 :  770\n"
     ]
    }
   ],
   "source": [
    "print(\"전체 데이터 개수 : \", len(df_x))\n",
    "\n",
    "# 전체 데이터개수를 k에 해당하는 5로 나누고 반올림\n",
    "print(\"각 데이터셋의 개수 : \", round(len(df_x)/5) )\n",
    "\n",
    "# 학습 데이터의 개수  \n",
    "print(\"학습 데이터 개수 : \", round(len(df_x)/5 * 4) )\n",
    "\n",
    "# 테스트 데이터의 개수  \n",
    "print(\"테스트 데이터 개수 : \", (len(df_x)- round(len(df_x)/5 * 4)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c092881",
   "metadata": {},
   "source": [
    "### 5. 딥러닝 모델 설계, 컴파일 및 실행하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8004bdf6",
   "metadata": {},
   "source": [
    "MAE를 한 번 시행할 때마다 저장하여 한꺼번에 보여줄 수 있게 mae 리스트를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42c71ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = []\n",
    "loss = []\n",
    "stage = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0ecdf7",
   "metadata": {},
   "source": [
    "아래의 for문은 n_fold만큼 반복된다.  \n",
    "데이터셋을 skf.split(df_x, df_y)를 이용해 학습 데이터셋과 테스트 데이터셋으로 나눈 후, 각각 train과 test에 할당한다.  \n",
    "n_fold 마다 셔플이 적용되어 학습 데이터셋과 테스트 데이터셋이 교차될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf1465e",
   "metadata": {},
   "source": [
    "df_x, df_y는 각각 3852개의 데이터가 있는 상태이며 skf로 셋팅된 환경으로 train, test로 shuffle되어 split된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c02b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e37e65d",
   "metadata": {},
   "source": [
    "학습 조기 종료를 위한 EarlyStopping() 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3800b6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8eff701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============  training 데이터 개수 :  3081 , test 데이터 개수 :  771 ==============\n",
      "-> K = 5 : 1 번째 그룹에 있는 test 데이터셋 사용 \n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "309/309 - 1s - loss: 26.7387 - mae: 4.1885 - val_loss: 13.7234 - val_mae: 2.9202\n",
      "Epoch 2/50\n",
      "309/309 - 0s - loss: 10.4804 - mae: 2.4342 - val_loss: 8.3090 - val_mae: 2.0435\n",
      "Epoch 3/50\n",
      "309/309 - 0s - loss: 7.3445 - mae: 1.9618 - val_loss: 6.7035 - val_mae: 1.8381\n",
      "Epoch 4/50\n",
      "309/309 - 0s - loss: 6.3312 - mae: 1.8197 - val_loss: 5.9757 - val_mae: 1.7711\n",
      "Epoch 5/50\n",
      "309/309 - 0s - loss: 5.7522 - mae: 1.7287 - val_loss: 5.6292 - val_mae: 1.7308\n",
      "Epoch 6/50\n",
      "309/309 - 0s - loss: 5.5017 - mae: 1.6807 - val_loss: 5.4148 - val_mae: 1.6231\n",
      "Epoch 7/50\n",
      "309/309 - 0s - loss: 5.4396 - mae: 1.6729 - val_loss: 5.5279 - val_mae: 1.7463\n",
      "Epoch 8/50\n",
      "309/309 - 0s - loss: 5.3539 - mae: 1.6638 - val_loss: 5.5547 - val_mae: 1.5890\n",
      "Epoch 9/50\n",
      "309/309 - 0s - loss: 5.3156 - mae: 1.6479 - val_loss: 5.4142 - val_mae: 1.5881\n",
      "Epoch 10/50\n",
      "309/309 - 0s - loss: 5.2968 - mae: 1.6452 - val_loss: 5.2940 - val_mae: 1.6206\n",
      "Epoch 11/50\n",
      "309/309 - 0s - loss: 5.2558 - mae: 1.6419 - val_loss: 5.4603 - val_mae: 1.5843\n",
      "Epoch 12/50\n",
      "309/309 - 0s - loss: 5.3052 - mae: 1.6470 - val_loss: 5.4388 - val_mae: 1.5840\n",
      "Epoch 13/50\n",
      "309/309 - 0s - loss: 5.3009 - mae: 1.6471 - val_loss: 5.3413 - val_mae: 1.5978\n",
      "Epoch 14/50\n",
      "309/309 - 0s - loss: 5.3178 - mae: 1.6493 - val_loss: 5.2885 - val_mae: 1.6412\n",
      "Epoch 15/50\n",
      "309/309 - 0s - loss: 5.2716 - mae: 1.6422 - val_loss: 5.2630 - val_mae: 1.6216\n",
      "Epoch 16/50\n",
      "309/309 - 0s - loss: 5.2594 - mae: 1.6436 - val_loss: 5.2815 - val_mae: 1.6221\n",
      "Epoch 17/50\n",
      "309/309 - 0s - loss: 5.2782 - mae: 1.6407 - val_loss: 5.3414 - val_mae: 1.5880\n",
      "Epoch 18/50\n",
      "309/309 - 0s - loss: 5.3193 - mae: 1.6319 - val_loss: 5.6743 - val_mae: 1.8022\n",
      "Epoch 19/50\n",
      "309/309 - 0s - loss: 5.2654 - mae: 1.6414 - val_loss: 5.3455 - val_mae: 1.6785\n",
      "Epoch 20/50\n",
      "309/309 - 0s - loss: 5.3044 - mae: 1.6479 - val_loss: 5.3513 - val_mae: 1.5859\n",
      "Epoch 21/50\n",
      "309/309 - 0s - loss: 5.3236 - mae: 1.6540 - val_loss: 5.4200 - val_mae: 1.5814\n",
      "Epoch 22/50\n",
      "309/309 - 0s - loss: 5.2560 - mae: 1.6425 - val_loss: 5.2540 - val_mae: 1.5981\n",
      "Epoch 23/50\n",
      "309/309 - 0s - loss: 5.2706 - mae: 1.6418 - val_loss: 5.6710 - val_mae: 1.5913\n",
      "Epoch 24/50\n",
      "309/309 - 0s - loss: 5.2368 - mae: 1.6342 - val_loss: 5.2509 - val_mae: 1.6150\n",
      "Epoch 25/50\n",
      "309/309 - 0s - loss: 5.2461 - mae: 1.6291 - val_loss: 5.2534 - val_mae: 1.6472\n",
      "Epoch 26/50\n",
      "309/309 - 0s - loss: 5.2564 - mae: 1.6399 - val_loss: 5.2245 - val_mae: 1.6117\n",
      "Epoch 27/50\n",
      "309/309 - 0s - loss: 5.2280 - mae: 1.6341 - val_loss: 5.3289 - val_mae: 1.6850\n",
      "Epoch 28/50\n",
      "309/309 - 0s - loss: 5.2449 - mae: 1.6396 - val_loss: 5.4056 - val_mae: 1.5725\n",
      "Epoch 29/50\n",
      "309/309 - 0s - loss: 5.2290 - mae: 1.6303 - val_loss: 5.2285 - val_mae: 1.6225\n",
      "Epoch 30/50\n",
      "309/309 - 0s - loss: 5.2660 - mae: 1.6416 - val_loss: 5.2803 - val_mae: 1.5786\n",
      "Epoch 31/50\n",
      "309/309 - 0s - loss: 5.2480 - mae: 1.6408 - val_loss: 5.2122 - val_mae: 1.6067\n",
      "Epoch 32/50\n",
      "309/309 - 0s - loss: 5.2324 - mae: 1.6350 - val_loss: 5.2238 - val_mae: 1.6438\n",
      "Epoch 33/50\n",
      "309/309 - 0s - loss: 5.1926 - mae: 1.6245 - val_loss: 5.4098 - val_mae: 1.5798\n",
      "Epoch 34/50\n",
      "309/309 - 0s - loss: 5.2896 - mae: 1.6396 - val_loss: 5.2180 - val_mae: 1.6043\n",
      "Epoch 35/50\n",
      "309/309 - 0s - loss: 5.2406 - mae: 1.6352 - val_loss: 5.4359 - val_mae: 1.7421\n",
      "Epoch 36/50\n",
      "309/309 - 0s - loss: 5.2375 - mae: 1.6273 - val_loss: 5.3477 - val_mae: 1.5765\n",
      "Epoch 37/50\n",
      "309/309 - 0s - loss: 5.1610 - mae: 1.6245 - val_loss: 5.2133 - val_mae: 1.5848\n",
      "Epoch 38/50\n",
      "309/309 - 0s - loss: 5.2269 - mae: 1.6279 - val_loss: 5.4245 - val_mae: 1.5737\n",
      "Epoch 39/50\n",
      "309/309 - 0s - loss: 5.2425 - mae: 1.6338 - val_loss: 5.1873 - val_mae: 1.6084\n",
      "Epoch 40/50\n",
      "309/309 - 0s - loss: 5.1838 - mae: 1.6187 - val_loss: 5.3650 - val_mae: 1.7208\n",
      "Epoch 41/50\n",
      "309/309 - 0s - loss: 5.2103 - mae: 1.6307 - val_loss: 5.2678 - val_mae: 1.5709\n",
      "Epoch 42/50\n",
      "309/309 - 0s - loss: 5.1900 - mae: 1.6249 - val_loss: 5.2092 - val_mae: 1.5742\n",
      "Epoch 43/50\n",
      "309/309 - 0s - loss: 5.2419 - mae: 1.6302 - val_loss: 5.1746 - val_mae: 1.5893\n",
      "Epoch 44/50\n",
      "309/309 - 0s - loss: 5.2222 - mae: 1.6297 - val_loss: 5.9038 - val_mae: 1.8926\n",
      "Epoch 45/50\n",
      "309/309 - 0s - loss: 5.2068 - mae: 1.6256 - val_loss: 5.2163 - val_mae: 1.5758\n",
      "Epoch 46/50\n",
      "309/309 - 0s - loss: 5.1793 - mae: 1.6247 - val_loss: 5.2608 - val_mae: 1.5733\n",
      "Epoch 47/50\n",
      "309/309 - 0s - loss: 5.2134 - mae: 1.6290 - val_loss: 5.2279 - val_mae: 1.5704\n",
      "Epoch 48/50\n",
      "309/309 - 0s - loss: 5.2065 - mae: 1.6136 - val_loss: 5.1863 - val_mae: 1.6388\n",
      "Epoch 49/50\n",
      "309/309 - 0s - loss: 5.1939 - mae: 1.6332 - val_loss: 5.4398 - val_mae: 1.5675\n",
      "Epoch 50/50\n",
      "309/309 - 0s - loss: 5.1366 - mae: 1.6141 - val_loss: 5.1359 - val_mae: 1.6091\n",
      "97/97 - 0s - loss: 5.1088 - mae: 1.6383\n",
      "-> Test dataset evaluation : Loss = 5.1088\n",
      "-> Test dataset evaluation : MAE = 1.6383\n",
      "==============  training 데이터 개수 :  3081 , test 데이터 개수 :  771 ==============\n",
      "-> K = 5 : 2 번째 그룹에 있는 test 데이터셋 사용 \n",
      "Epoch 1/50\n",
      "309/309 - 0s - loss: 17.4889 - mae: 3.4074 - val_loss: 13.4099 - val_mae: 2.9335\n",
      "Epoch 2/50\n",
      "309/309 - 0s - loss: 8.5375 - mae: 2.1459 - val_loss: 6.3114 - val_mae: 1.8632\n",
      "Epoch 3/50\n",
      "309/309 - 0s - loss: 5.9476 - mae: 1.7516 - val_loss: 5.5678 - val_mae: 1.7427\n",
      "Epoch 4/50\n",
      "309/309 - 0s - loss: 5.5709 - mae: 1.7080 - val_loss: 5.6210 - val_mae: 1.6402\n",
      "Epoch 5/50\n",
      "309/309 - 0s - loss: 5.4640 - mae: 1.6789 - val_loss: 5.4341 - val_mae: 1.7527\n",
      "Epoch 6/50\n",
      "309/309 - 0s - loss: 5.4573 - mae: 1.6741 - val_loss: 5.3493 - val_mae: 1.6326\n",
      "Epoch 7/50\n",
      "309/309 - 0s - loss: 5.2932 - mae: 1.6488 - val_loss: 5.2618 - val_mae: 1.6658\n",
      "Epoch 8/50\n",
      "309/309 - 0s - loss: 5.3466 - mae: 1.6501 - val_loss: 5.8190 - val_mae: 1.6154\n",
      "Epoch 9/50\n",
      "309/309 - 0s - loss: 5.3629 - mae: 1.6483 - val_loss: 5.2531 - val_mae: 1.6925\n",
      "Epoch 10/50\n",
      "309/309 - 0s - loss: 5.2476 - mae: 1.6388 - val_loss: 5.3380 - val_mae: 1.7308\n",
      "Epoch 11/50\n",
      "309/309 - 0s - loss: 5.2776 - mae: 1.6471 - val_loss: 5.2824 - val_mae: 1.7061\n",
      "Epoch 12/50\n",
      "309/309 - 0s - loss: 5.3016 - mae: 1.6424 - val_loss: 5.2984 - val_mae: 1.6031\n",
      "Epoch 13/50\n",
      "309/309 - 0s - loss: 5.2479 - mae: 1.6328 - val_loss: 5.5005 - val_mae: 1.5971\n",
      "Epoch 14/50\n",
      "309/309 - 0s - loss: 5.2262 - mae: 1.6346 - val_loss: 5.5320 - val_mae: 1.5937\n",
      "Epoch 15/50\n",
      "309/309 - 0s - loss: 5.1987 - mae: 1.6237 - val_loss: 5.2943 - val_mae: 1.5877\n",
      "Epoch 16/50\n",
      "309/309 - 0s - loss: 5.2329 - mae: 1.6338 - val_loss: 5.1668 - val_mae: 1.6211\n",
      "Epoch 17/50\n",
      "309/309 - 0s - loss: 5.2409 - mae: 1.6275 - val_loss: 5.1724 - val_mae: 1.6647\n",
      "Epoch 18/50\n",
      "309/309 - 0s - loss: 5.2331 - mae: 1.6229 - val_loss: 5.2013 - val_mae: 1.5992\n",
      "Epoch 19/50\n",
      "309/309 - 0s - loss: 5.2265 - mae: 1.6190 - val_loss: 5.1828 - val_mae: 1.6623\n",
      "Epoch 20/50\n",
      "309/309 - 0s - loss: 5.1559 - mae: 1.6223 - val_loss: 5.1728 - val_mae: 1.6540\n",
      "Epoch 21/50\n",
      "309/309 - 0s - loss: 5.1476 - mae: 1.6186 - val_loss: 5.2834 - val_mae: 1.5791\n",
      "Epoch 22/50\n",
      "309/309 - 0s - loss: 5.1089 - mae: 1.6103 - val_loss: 5.2191 - val_mae: 1.6880\n",
      "Epoch 23/50\n",
      "309/309 - 0s - loss: 5.2516 - mae: 1.6232 - val_loss: 5.2098 - val_mae: 1.6785\n",
      "Epoch 24/50\n",
      "309/309 - 0s - loss: 5.1683 - mae: 1.6145 - val_loss: 5.1531 - val_mae: 1.6053\n",
      "Epoch 25/50\n",
      "309/309 - 0s - loss: 5.0908 - mae: 1.6032 - val_loss: 5.1411 - val_mae: 1.6331\n",
      "Epoch 26/50\n",
      "309/309 - 0s - loss: 5.1386 - mae: 1.6112 - val_loss: 5.2331 - val_mae: 1.6034\n",
      "Epoch 27/50\n",
      "309/309 - 0s - loss: 5.1276 - mae: 1.6058 - val_loss: 5.1988 - val_mae: 1.6779\n",
      "Epoch 28/50\n",
      "309/309 - 0s - loss: 5.1719 - mae: 1.6150 - val_loss: 5.1904 - val_mae: 1.6594\n",
      "Epoch 29/50\n",
      "309/309 - 0s - loss: 5.1036 - mae: 1.6146 - val_loss: 5.1534 - val_mae: 1.5892\n",
      "Epoch 30/50\n",
      "309/309 - 0s - loss: 5.1097 - mae: 1.6133 - val_loss: 5.1287 - val_mae: 1.6198\n",
      "Epoch 31/50\n",
      "309/309 - 0s - loss: 5.1045 - mae: 1.6042 - val_loss: 5.1746 - val_mae: 1.6365\n",
      "Epoch 32/50\n",
      "309/309 - 0s - loss: 5.1099 - mae: 1.6086 - val_loss: 5.1985 - val_mae: 1.5944\n",
      "Epoch 33/50\n",
      "309/309 - 0s - loss: 5.0512 - mae: 1.5962 - val_loss: 5.2217 - val_mae: 1.6799\n",
      "Epoch 34/50\n",
      "309/309 - 0s - loss: 5.0702 - mae: 1.6039 - val_loss: 5.1485 - val_mae: 1.6258\n",
      "Epoch 35/50\n",
      "309/309 - 0s - loss: 5.0691 - mae: 1.5993 - val_loss: 5.6034 - val_mae: 1.5847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "309/309 - 0s - loss: 5.0673 - mae: 1.5989 - val_loss: 5.2060 - val_mae: 1.5911\n",
      "Epoch 37/50\n",
      "309/309 - 0s - loss: 4.9893 - mae: 1.5807 - val_loss: 5.2939 - val_mae: 1.7123\n",
      "Epoch 38/50\n",
      "309/309 - 0s - loss: 5.0769 - mae: 1.5955 - val_loss: 5.2477 - val_mae: 1.6947\n",
      "Epoch 39/50\n",
      "309/309 - 0s - loss: 5.0751 - mae: 1.6120 - val_loss: 5.1517 - val_mae: 1.6359\n",
      "Epoch 40/50\n",
      "309/309 - 0s - loss: 5.0796 - mae: 1.5970 - val_loss: 5.3342 - val_mae: 1.5721\n",
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "97/97 - 0s - loss: 5.0927 - mae: 1.5258\n",
      "-> Test dataset evaluation : Loss = 5.0927\n",
      "-> Test dataset evaluation : MAE = 1.5258\n",
      "==============  training 데이터 개수 :  3082 , test 데이터 개수 :  770 ==============\n",
      "-> K = 5 : 3 번째 그룹에 있는 test 데이터셋 사용 \n",
      "Epoch 1/50\n",
      "309/309 - 0s - loss: 29.9084 - mae: 4.3002 - val_loss: 15.0925 - val_mae: 3.1210\n",
      "Epoch 2/50\n",
      "309/309 - 0s - loss: 14.3638 - mae: 2.9634 - val_loss: 11.8738 - val_mae: 2.6593\n",
      "Epoch 3/50\n",
      "309/309 - 0s - loss: 11.3592 - mae: 2.5204 - val_loss: 9.3808 - val_mae: 2.2729\n",
      "Epoch 4/50\n",
      "309/309 - 0s - loss: 9.0328 - mae: 2.1748 - val_loss: 7.3946 - val_mae: 1.9400\n",
      "Epoch 5/50\n",
      "309/309 - 0s - loss: 7.4149 - mae: 1.9390 - val_loss: 6.2259 - val_mae: 1.8043\n",
      "Epoch 6/50\n",
      "309/309 - 0s - loss: 6.3659 - mae: 1.8073 - val_loss: 5.5337 - val_mae: 1.7803\n",
      "Epoch 7/50\n",
      "309/309 - 0s - loss: 5.7561 - mae: 1.7283 - val_loss: 5.1508 - val_mae: 1.5605\n",
      "Epoch 8/50\n",
      "309/309 - 0s - loss: 5.6409 - mae: 1.7022 - val_loss: 5.4469 - val_mae: 1.8308\n",
      "Epoch 9/50\n",
      "309/309 - 0s - loss: 5.5627 - mae: 1.6990 - val_loss: 4.9844 - val_mae: 1.5323\n",
      "Epoch 10/50\n",
      "309/309 - 0s - loss: 5.5640 - mae: 1.6893 - val_loss: 4.8345 - val_mae: 1.5489\n",
      "Epoch 11/50\n",
      "309/309 - 0s - loss: 5.4644 - mae: 1.6765 - val_loss: 5.5078 - val_mae: 1.5448\n",
      "Epoch 12/50\n",
      "309/309 - 0s - loss: 5.4953 - mae: 1.6800 - val_loss: 4.8170 - val_mae: 1.5356\n",
      "Epoch 13/50\n",
      "309/309 - 0s - loss: 5.4221 - mae: 1.6643 - val_loss: 4.9503 - val_mae: 1.6769\n",
      "Epoch 14/50\n",
      "309/309 - 0s - loss: 5.4462 - mae: 1.6690 - val_loss: 4.7992 - val_mae: 1.5244\n",
      "Epoch 15/50\n",
      "309/309 - 0s - loss: 5.4167 - mae: 1.6599 - val_loss: 4.7613 - val_mae: 1.5675\n",
      "Epoch 16/50\n",
      "309/309 - 0s - loss: 5.4848 - mae: 1.6752 - val_loss: 4.7811 - val_mae: 1.5224\n",
      "Epoch 17/50\n",
      "309/309 - 0s - loss: 5.4525 - mae: 1.6639 - val_loss: 4.8090 - val_mae: 1.6235\n",
      "Epoch 18/50\n",
      "309/309 - 0s - loss: 5.3813 - mae: 1.6548 - val_loss: 4.8690 - val_mae: 1.6560\n",
      "Epoch 19/50\n",
      "309/309 - 0s - loss: 5.4022 - mae: 1.6688 - val_loss: 5.0999 - val_mae: 1.7388\n",
      "Epoch 20/50\n",
      "309/309 - 0s - loss: 5.5354 - mae: 1.6769 - val_loss: 4.9399 - val_mae: 1.6855\n",
      "Epoch 21/50\n",
      "309/309 - 0s - loss: 5.3700 - mae: 1.6554 - val_loss: 5.0430 - val_mae: 1.4961\n",
      "Epoch 22/50\n",
      "309/309 - 0s - loss: 5.3895 - mae: 1.6496 - val_loss: 4.9436 - val_mae: 1.6952\n",
      "Epoch 23/50\n",
      "309/309 - 0s - loss: 5.3479 - mae: 1.6556 - val_loss: 5.1208 - val_mae: 1.5001\n",
      "Epoch 24/50\n",
      "309/309 - 0s - loss: 5.3891 - mae: 1.6547 - val_loss: 4.9003 - val_mae: 1.6745\n",
      "Epoch 25/50\n",
      "309/309 - 0s - loss: 5.3471 - mae: 1.6426 - val_loss: 4.7239 - val_mae: 1.5244\n",
      "Epoch 26/50\n",
      "309/309 - 0s - loss: 5.4103 - mae: 1.6622 - val_loss: 5.5663 - val_mae: 1.8823\n",
      "Epoch 27/50\n",
      "309/309 - 0s - loss: 5.3881 - mae: 1.6566 - val_loss: 5.0071 - val_mae: 1.4985\n",
      "Epoch 28/50\n",
      "309/309 - 0s - loss: 5.4548 - mae: 1.6701 - val_loss: 4.7227 - val_mae: 1.5183\n",
      "Epoch 29/50\n",
      "309/309 - 0s - loss: 5.3552 - mae: 1.6483 - val_loss: 4.7252 - val_mae: 1.5892\n",
      "Epoch 30/50\n",
      "309/309 - 0s - loss: 5.4016 - mae: 1.6556 - val_loss: 5.6432 - val_mae: 1.9148\n",
      "Epoch 31/50\n",
      "309/309 - 0s - loss: 5.3861 - mae: 1.6524 - val_loss: 4.6950 - val_mae: 1.5348\n",
      "Epoch 32/50\n",
      "309/309 - 0s - loss: 5.3172 - mae: 1.6377 - val_loss: 4.7005 - val_mae: 1.5730\n",
      "Epoch 33/50\n",
      "309/309 - 0s - loss: 5.3447 - mae: 1.6470 - val_loss: 4.7080 - val_mae: 1.5169\n",
      "Epoch 34/50\n",
      "309/309 - 0s - loss: 5.3694 - mae: 1.6485 - val_loss: 4.7071 - val_mae: 1.5184\n",
      "Epoch 35/50\n",
      "309/309 - 0s - loss: 5.3071 - mae: 1.6434 - val_loss: 4.6756 - val_mae: 1.5351\n",
      "Epoch 36/50\n",
      "309/309 - 0s - loss: 5.3023 - mae: 1.6404 - val_loss: 4.8202 - val_mae: 1.4921\n",
      "Epoch 37/50\n",
      "309/309 - 0s - loss: 5.4067 - mae: 1.6569 - val_loss: 4.7914 - val_mae: 1.6413\n",
      "Epoch 38/50\n",
      "309/309 - 0s - loss: 5.3002 - mae: 1.6351 - val_loss: 4.6688 - val_mae: 1.5499\n",
      "Epoch 39/50\n",
      "309/309 - 0s - loss: 5.3171 - mae: 1.6441 - val_loss: 4.6839 - val_mae: 1.5229\n",
      "Epoch 40/50\n",
      "309/309 - 0s - loss: 5.3265 - mae: 1.6441 - val_loss: 5.1126 - val_mae: 1.4972\n",
      "Epoch 41/50\n",
      "309/309 - 0s - loss: 5.3025 - mae: 1.6381 - val_loss: 4.6895 - val_mae: 1.5203\n",
      "Epoch 42/50\n",
      "309/309 - 0s - loss: 5.3009 - mae: 1.6338 - val_loss: 4.7066 - val_mae: 1.5973\n",
      "Epoch 43/50\n",
      "309/309 - 0s - loss: 5.2958 - mae: 1.6438 - val_loss: 4.7377 - val_mae: 1.5006\n",
      "Epoch 44/50\n",
      "309/309 - 0s - loss: 5.3053 - mae: 1.6405 - val_loss: 4.7229 - val_mae: 1.6130\n",
      "Epoch 45/50\n",
      "309/309 - 0s - loss: 5.3302 - mae: 1.6424 - val_loss: 4.8800 - val_mae: 1.4914\n",
      "Epoch 46/50\n",
      "309/309 - 0s - loss: 5.3567 - mae: 1.6517 - val_loss: 4.7057 - val_mae: 1.5072\n",
      "Epoch 47/50\n",
      "309/309 - 0s - loss: 5.3130 - mae: 1.6408 - val_loss: 4.7049 - val_mae: 1.5102\n",
      "Epoch 48/50\n",
      "309/309 - 0s - loss: 5.3321 - mae: 1.6469 - val_loss: 4.7152 - val_mae: 1.5139\n",
      "97/97 - 0s - loss: 5.2180 - mae: 1.5927\n",
      "-> Test dataset evaluation : Loss = 5.2180\n",
      "-> Test dataset evaluation : MAE = 1.5927\n",
      "==============  training 데이터 개수 :  3082 , test 데이터 개수 :  770 ==============\n",
      "-> K = 5 : 4 번째 그룹에 있는 test 데이터셋 사용 \n",
      "Epoch 1/50\n",
      "309/309 - 0s - loss: 16.9612 - mae: 3.3473 - val_loss: 13.8966 - val_mae: 2.9824\n",
      "Epoch 2/50\n",
      "309/309 - 0s - loss: 11.4809 - mae: 2.6294 - val_loss: 9.1325 - val_mae: 2.2729\n",
      "Epoch 3/50\n",
      "309/309 - 0s - loss: 7.8163 - mae: 2.0366 - val_loss: 6.8698 - val_mae: 1.8127\n",
      "Epoch 4/50\n",
      "309/309 - 0s - loss: 6.3050 - mae: 1.8060 - val_loss: 5.9088 - val_mae: 1.7431\n",
      "Epoch 5/50\n",
      "309/309 - 0s - loss: 5.8696 - mae: 1.7607 - val_loss: 5.6780 - val_mae: 1.7468\n",
      "Epoch 6/50\n",
      "309/309 - 0s - loss: 5.6282 - mae: 1.7210 - val_loss: 5.7023 - val_mae: 1.6675\n",
      "Epoch 7/50\n",
      "309/309 - 0s - loss: 5.5840 - mae: 1.7062 - val_loss: 5.7186 - val_mae: 1.7711\n",
      "Epoch 8/50\n",
      "309/309 - 0s - loss: 5.4517 - mae: 1.6853 - val_loss: 5.5362 - val_mae: 1.7200\n",
      "Epoch 9/50\n",
      "309/309 - 0s - loss: 5.3841 - mae: 1.6702 - val_loss: 5.5935 - val_mae: 1.7433\n",
      "Epoch 10/50\n",
      "309/309 - 0s - loss: 5.3667 - mae: 1.6745 - val_loss: 5.5261 - val_mae: 1.6474\n",
      "Epoch 11/50\n",
      "309/309 - 0s - loss: 5.3799 - mae: 1.6650 - val_loss: 5.7029 - val_mae: 1.7849\n",
      "Epoch 12/50\n",
      "309/309 - 0s - loss: 5.3439 - mae: 1.6682 - val_loss: 5.4950 - val_mae: 1.6756\n",
      "Epoch 13/50\n",
      "309/309 - 0s - loss: 5.3470 - mae: 1.6607 - val_loss: 5.5506 - val_mae: 1.7158\n",
      "Epoch 14/50\n",
      "309/309 - 0s - loss: 5.4005 - mae: 1.6716 - val_loss: 5.5388 - val_mae: 1.7103\n",
      "Epoch 15/50\n",
      "309/309 - 0s - loss: 5.2741 - mae: 1.6457 - val_loss: 5.7814 - val_mae: 1.7758\n",
      "Epoch 16/50\n",
      "309/309 - 0s - loss: 5.4018 - mae: 1.6701 - val_loss: 6.1654 - val_mae: 1.9117\n",
      "Epoch 17/50\n",
      "309/309 - 0s - loss: 5.2577 - mae: 1.6495 - val_loss: 5.5353 - val_mae: 1.6532\n",
      "Epoch 18/50\n",
      "309/309 - 0s - loss: 5.3207 - mae: 1.6490 - val_loss: 5.5582 - val_mae: 1.7245\n",
      "Epoch 19/50\n",
      "309/309 - 0s - loss: 5.2302 - mae: 1.6361 - val_loss: 5.5462 - val_mae: 1.6326\n",
      "Epoch 20/50\n",
      "309/309 - 0s - loss: 5.2332 - mae: 1.6458 - val_loss: 5.6040 - val_mae: 1.6360\n",
      "Epoch 21/50\n",
      "309/309 - 0s - loss: 5.3021 - mae: 1.6503 - val_loss: 5.5257 - val_mae: 1.6761\n",
      "Epoch 22/50\n",
      "309/309 - 0s - loss: 5.1987 - mae: 1.6307 - val_loss: 5.5313 - val_mae: 1.6570\n",
      "97/97 - 0s - loss: 5.1104 - mae: 1.5814\n",
      "-> Test dataset evaluation : Loss = 5.1104\n",
      "-> Test dataset evaluation : MAE = 1.5814\n",
      "==============  training 데이터 개수 :  3082 , test 데이터 개수 :  770 ==============\n",
      "-> K = 5 : 5 번째 그룹에 있는 test 데이터셋 사용 \n",
      "Epoch 1/50\n",
      "309/309 - 0s - loss: 22.4564 - mae: 3.8781 - val_loss: 15.7094 - val_mae: 3.1417\n",
      "Epoch 2/50\n",
      "309/309 - 0s - loss: 14.5495 - mae: 3.0148 - val_loss: 11.3197 - val_mae: 2.5035\n",
      "Epoch 3/50\n",
      "309/309 - 0s - loss: 10.1052 - mae: 2.3546 - val_loss: 8.5044 - val_mae: 2.0628\n",
      "Epoch 4/50\n",
      "309/309 - 0s - loss: 7.8801 - mae: 2.0604 - val_loss: 7.3943 - val_mae: 2.0344\n",
      "Epoch 5/50\n",
      "309/309 - 0s - loss: 6.8516 - mae: 1.9153 - val_loss: 6.5989 - val_mae: 1.8452\n",
      "Epoch 6/50\n",
      "309/309 - 0s - loss: 6.3218 - mae: 1.8363 - val_loss: 6.1866 - val_mae: 1.7470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "309/309 - 0s - loss: 5.8909 - mae: 1.7686 - val_loss: 5.8244 - val_mae: 1.7389\n",
      "Epoch 8/50\n",
      "309/309 - 0s - loss: 5.6907 - mae: 1.7330 - val_loss: 5.6762 - val_mae: 1.7857\n",
      "Epoch 9/50\n",
      "309/309 - 0s - loss: 5.5109 - mae: 1.6974 - val_loss: 5.5487 - val_mae: 1.7538\n",
      "Epoch 10/50\n",
      "309/309 - 0s - loss: 5.4993 - mae: 1.6958 - val_loss: 5.4758 - val_mae: 1.6753\n",
      "Epoch 11/50\n",
      "309/309 - 0s - loss: 5.4679 - mae: 1.6875 - val_loss: 5.4935 - val_mae: 1.6489\n",
      "Epoch 12/50\n",
      "309/309 - 0s - loss: 5.4301 - mae: 1.6863 - val_loss: 5.4309 - val_mae: 1.7137\n",
      "Epoch 13/50\n",
      "309/309 - 0s - loss: 5.4489 - mae: 1.6845 - val_loss: 5.5551 - val_mae: 1.7987\n",
      "Epoch 14/50\n",
      "309/309 - 0s - loss: 5.3733 - mae: 1.6698 - val_loss: 5.6036 - val_mae: 1.8177\n",
      "Epoch 15/50\n",
      "309/309 - 0s - loss: 5.3141 - mae: 1.6644 - val_loss: 5.4211 - val_mae: 1.6454\n",
      "Epoch 16/50\n",
      "309/309 - 0s - loss: 5.3999 - mae: 1.6781 - val_loss: 5.4828 - val_mae: 1.6177\n",
      "Epoch 17/50\n",
      "309/309 - 0s - loss: 5.3037 - mae: 1.6458 - val_loss: 5.4488 - val_mae: 1.7721\n",
      "Epoch 18/50\n",
      "309/309 - 0s - loss: 5.3604 - mae: 1.6631 - val_loss: 5.5745 - val_mae: 1.8157\n",
      "Epoch 19/50\n",
      "309/309 - 0s - loss: 5.2908 - mae: 1.6481 - val_loss: 5.3503 - val_mae: 1.6845\n",
      "Epoch 20/50\n",
      "309/309 - 0s - loss: 5.2692 - mae: 1.6446 - val_loss: 5.5123 - val_mae: 1.7953\n",
      "Epoch 21/50\n",
      "309/309 - 0s - loss: 5.2635 - mae: 1.6389 - val_loss: 5.3281 - val_mae: 1.6463\n",
      "Epoch 22/50\n",
      "309/309 - 0s - loss: 5.3284 - mae: 1.6589 - val_loss: 5.4633 - val_mae: 1.7642\n",
      "Epoch 23/50\n",
      "309/309 - 0s - loss: 5.2727 - mae: 1.6498 - val_loss: 5.3802 - val_mae: 1.7167\n",
      "Epoch 24/50\n",
      "309/309 - 0s - loss: 5.2610 - mae: 1.6446 - val_loss: 5.2931 - val_mae: 1.6546\n",
      "Epoch 25/50\n",
      "309/309 - 0s - loss: 5.2477 - mae: 1.6429 - val_loss: 5.4178 - val_mae: 1.6297\n",
      "Epoch 26/50\n",
      "309/309 - 0s - loss: 5.2729 - mae: 1.6491 - val_loss: 5.7863 - val_mae: 1.8850\n",
      "Epoch 27/50\n",
      "309/309 - 0s - loss: 5.2871 - mae: 1.6465 - val_loss: 6.4553 - val_mae: 2.0632\n",
      "Epoch 28/50\n",
      "309/309 - 0s - loss: 5.3232 - mae: 1.6661 - val_loss: 5.3863 - val_mae: 1.6115\n",
      "Epoch 29/50\n",
      "309/309 - 0s - loss: 5.2316 - mae: 1.6415 - val_loss: 5.3792 - val_mae: 1.7141\n",
      "Epoch 30/50\n",
      "309/309 - 0s - loss: 5.2860 - mae: 1.6576 - val_loss: 5.3051 - val_mae: 1.6905\n",
      "Epoch 31/50\n",
      "309/309 - 0s - loss: 5.2309 - mae: 1.6436 - val_loss: 5.3751 - val_mae: 1.7238\n",
      "Epoch 32/50\n",
      "309/309 - 0s - loss: 5.2131 - mae: 1.6273 - val_loss: 5.5341 - val_mae: 1.7965\n",
      "Epoch 33/50\n",
      "309/309 - 0s - loss: 5.2865 - mae: 1.6547 - val_loss: 5.4037 - val_mae: 1.7313\n",
      "Epoch 34/50\n",
      "309/309 - 0s - loss: 5.1969 - mae: 1.6313 - val_loss: 5.9574 - val_mae: 1.9300\n",
      "97/97 - 0s - loss: 5.6316 - mae: 1.8288\n",
      "-> Test dataset evaluation : Loss = 5.6316\n",
      "-> Test dataset evaluation : MAE = 1.8288\n"
     ]
    }
   ],
   "source": [
    "for train, test in skf.split(df_x, df_y): # skf로 셋팅된 환경에서 정의한 n_fold만큼 반복\n",
    "    print(\"=\"*14, \" training 데이터 개수 : \", len(train), \", test 데이터 개수 : \", len(test), \"=\"*14)\n",
    "    stage += 1\n",
    "    print(\"-> K = %d : %d 번째 그룹에 있는 test 데이터셋 사용 \" %(n_fold, stage))\n",
    "    \n",
    "    # 딥러닝 구조를 결정(모델을 설정), n_fold 번 반복됨\n",
    "    # 이전 딥러닝 모델1과 같은 구조로 설정하여 검증 방식에 따른 정확도 차이 비교를 하고자 한다. \n",
    "    model = Sequential()\n",
    "    #1번째 층 : 입력 x는 9개, 출력은 12개, 활성화함수 relu \n",
    "    model.add(Dense(12, input_dim=9, activation='relu'))\n",
    "    #2번째 층 : 입력 x는 12개, 출력은 9개, 활성화함수 relu \n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    #3번째 층 : 입력 x는 9개, 출력은 1개, 활성화함수 linear\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    # 모델 컴파일    \n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    \n",
    "    # 모델 실행\n",
    "    # 학습 데이터셋을 통한 학습: verbose가 2이면 함축적인 정보만 출력, epochs와 batch_sizes는 이전 모델과 동일하다.\n",
    "    model.fit(df_x[train], df_y[train], validation_data=(df_x[test],df_y[test]), epochs=50, batch_size=10, verbose=2, callbacks=[early_stopping])\n",
    "   \n",
    "    # 테스트 데이터셋을 통한 검증 \n",
    "    # 테스트 데이터셋 loss, mae(mae로 선형회귀 모델의 정확도 평가)\n",
    "    k_loss, k_mae = model.evaluate(x=df_x[train], y=df_y[train], verbose=2)    \n",
    "    # 테스트 데이터셋의 loss\n",
    "    print(\"-> Test dataset evaluation : Loss = {:.4f}\".format(k_loss))   \n",
    "    # 테스트 데이터셋의 MAE\n",
    "    print(\"-> Test dataset evaluation : MAE = {:.4f}\".format(k_mae))\n",
    "    \n",
    "    # save k_loss to loss list\n",
    "    loss.append(k_loss)\n",
    "    \n",
    "    # save k_mae to mae list\n",
    "    mae.append(k_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd914298",
   "metadata": {},
   "source": [
    "### 6. 딥러닝 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab43460",
   "metadata": {},
   "source": [
    "#### Loss(mse)를 K에 해당하는 횟수만큼 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "959e4dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K 값 :  5 \n",
      "Loss :  [5.108787536621094, 5.092702388763428, 5.218003273010254, 5.110355854034424, 5.631595134735107]\n"
     ]
    }
   ],
   "source": [
    "print(\"K 값 :  %.f \" % n_fold)\n",
    "print(\"Loss : \", loss) #loss 리스트 값 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7f2108",
   "metadata": {},
   "source": [
    "#### MAE를 K에 해당하는 횟수만큼 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "baabf1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K 값 :  5 \n",
      "MAE :  [1.6383311748504639, 1.5257914066314697, 1.5927362442016602, 1.5813932418823242, 1.8288325071334839]\n"
     ]
    }
   ],
   "source": [
    "print(\"K 값 :  %.f \" % n_fold)\n",
    "print(\"MAE : \", mae) # mae 리스트 값 출력 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eba516a",
   "metadata": {},
   "source": [
    "#### 테스트 데이터셋을 기반으로 K번 iteration이 적용된 MSE 및 MAE의 평균값 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8a16289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "\n",
      " MSE : 5.2323\n"
     ]
    }
   ],
   "source": [
    "# 리스트형을 넘파이에서 제공하는 배열로 변환 \n",
    "mse_ave = np.array(loss)\n",
    "print(type(mse_ave)) \n",
    "print(\"\\n MSE : %.4f\" %(mse_ave.mean()))  # mse 평균값 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef3e426c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "\n",
      " MAE : 1.6334\n"
     ]
    }
   ],
   "source": [
    "mae_ave = np.array(mae)\n",
    "print(type(mae_ave)) \n",
    "print(\"\\n MAE : %.4f\" %(mae_ave.mean()))  # mae 평균값 출력 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7944fe60",
   "metadata": {},
   "source": [
    "MAE 값이 1.6262가 나왔으므로 꽃게 나이 예측의 평균적인 오차값은 1.6262개월이라는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb1d2a4",
   "metadata": {},
   "source": [
    "### 7. 새로운 데이터를 위의 딥러닝 모델을 사용하여 예측하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5ef86d",
   "metadata": {},
   "source": [
    "keras의 Sequential 모델에서 제공하는 predict() 함수를 사용  \n",
    "아직 학습과 테스트에 사용하지 않은 데이터를 사용해 예측하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f08331ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crab1 나이 예측 : 11 개월\n",
      "crab2 나이 예측 : 8 개월\n"
     ]
    }
   ],
   "source": [
    "# Length, Diameter, Height, Weight, Viscera Weight, Shell Weight, Sex_F, Sex_I, Sex_M\n",
    "crab1 = np.array([[1.5305, 1.185, 0.4135, 24.7356155, 5.5858415, 6.749191, 1, 0, 0]])\n",
    "crab2 = np.array([[0.8975,0.67,0.2305,5.50050975,1.37645075,1.5602225,0,0,1]])\n",
    "\n",
    "test_crab1 = model.predict(crab1)\n",
    "test_crab2 = model.predict(crab2)\n",
    "\n",
    "print(\"crab1 나이 예측 : %.f\" %test_crab1, \"개월\")\n",
    "print(\"crab2 나이 예측 : %.f\" %test_crab2, \"개월\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c5e82e",
   "metadata": {},
   "source": [
    "실제 데이터를 바탕으로 만든 가상의 꽃게 데이터에서 딥러닝 모델이 꽤 정확하게 동작함을 확인할 수 있었다.  \n",
    "crab1은 데이터 셋의 첫 번째 crab 데이터의 각 독립변수들을 조금씩 증가시켜 생후 11개월 정도의 crab을 만들었고, crab2는 데이터 셋의 두 번째 crab 데이터의 각 독립변수들을 조금씩 증가시켜 생후 8개월 정도의 crab을 만든 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a58d902",
   "metadata": {},
   "source": [
    "### 8. 학습 모델 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0cf1f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('CrabAge2.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b58e7d",
   "metadata": {},
   "source": [
    "### 9. 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3876578e",
   "metadata": {},
   "source": [
    "데이터셋의 꽃게의 나이가 5 ~ 23개월이기 때문에 꽃게 나이 예측의 평균적인 오차값이 1.6262개월인 것은 상당히 예측이 잘 되었다고 생각한다. 그러나 처음 만든 홀드 아웃 교차 검증을 사용한 딥러닝 모델 1(오차값: 1.5869개월)에 비해서 오차값이 크고, K겹 교차 검증 방식 자체가 시간이 상당히 오래 걸리는 검증 방식이기 때문에 비효율적이라고 생각한다. 여기에서 사용한 딥러닝 모델 2의 오차가 더 크게 나타난 이유는 mae 리스트의 4번 째 원소를 보면 알 수 있다. 과적합을 막기 위해 EarlyStopping()을 사용했는데 4번째 iteration에서 10번째로 성능이 개선되지 않는 부분에서 학습을 멈추었고, 그 결과 MAE 값이 1.8284177780151367 라는 상대적으로 큰 수치가 나오게 되었다. 이는 MAE의 평균을 높이는 큰 요인이 되었다. 이를 통해 k겹 교차 검증에서는 EarlyStopping() 함수를 사용하면 우연히 MAE가 큰 지점에서 학습을 멈출 수 있으므로 좋지 않다는 생각이 들었다. 이는 EarlyStopping() 함수를 사용하지 않는 3번 째 모델에서 확인을 할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ce2922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
