{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660a4475",
   "metadata": {},
   "source": [
    "## 남방톱날꽃게(청게)의 나이 예측 딥러닝 모델 구현 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282a42cb",
   "metadata": {},
   "source": [
    "본 소스 파일에서는 이전의 모델 1과는 다르게 과적합 예방을 위해 K겹 교차 검증 방식(K-fold Cross Validation)을 사용하였다.  \n",
    "이전 딥러닝 모델 2와는 달리 EarlyStopping() 함수는 사용하지 않았다. 정확한 비교를 위해 다른 부분은 같게 설정하였다.   \n",
    "다중 선형 회귀 분석의 방법을 사용하여 정확도를 MAE(Mean Absolute Error)를 이용해 평가하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d6c55e",
   "metadata": {},
   "source": [
    "### 1. 필요한 라이브러리 import하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcff1ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager   # 한글 사용을 위해 import\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c90658",
   "metadata": {},
   "source": [
    "tensorflow 버전 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ff4929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b46fbbc",
   "metadata": {},
   "source": [
    "tensorboard import & version 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f80c72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorboard\n",
    "\n",
    "tensorboard.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d16c70",
   "metadata": {},
   "source": [
    "### 2. 데이터셋 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e268d3",
   "metadata": {},
   "source": [
    "상대경로를 사용하여 최종적으로 가공된 데이터셋을 가져온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e22db6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"./3_Dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6850948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e960f4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Viscera Weight</th>\n",
       "      <th>Shell Weight</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4375</td>\n",
       "      <td>1.1750</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>24.635715</td>\n",
       "      <td>5.584852</td>\n",
       "      <td>6.747181</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>5.400580</td>\n",
       "      <td>1.374951</td>\n",
       "      <td>1.559222</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0375</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>7.952035</td>\n",
       "      <td>1.601747</td>\n",
       "      <td>2.764076</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1750</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>13.480187</td>\n",
       "      <td>2.282135</td>\n",
       "      <td>5.244657</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>6.903103</td>\n",
       "      <td>1.488349</td>\n",
       "      <td>1.700970</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>1.4625</td>\n",
       "      <td>1.1375</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>24.819987</td>\n",
       "      <td>5.854172</td>\n",
       "      <td>6.378637</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848</th>\n",
       "      <td>1.5500</td>\n",
       "      <td>1.2125</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>34.458817</td>\n",
       "      <td>7.172423</td>\n",
       "      <td>9.780577</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>2.012815</td>\n",
       "      <td>0.524466</td>\n",
       "      <td>0.637864</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>1.0625</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>10.347568</td>\n",
       "      <td>2.338834</td>\n",
       "      <td>2.976698</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.6125</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>4.068153</td>\n",
       "      <td>1.346601</td>\n",
       "      <td>1.417475</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3852 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Length  Diameter  Height     Weight  Viscera Weight  Shell Weight  Age  \\\n",
       "0     1.4375    1.1750  0.4125  24.635715        5.584852      6.747181    9   \n",
       "1     0.8875    0.6500  0.2125   5.400580        1.374951      1.559222    6   \n",
       "2     1.0375    0.7750  0.2500   7.952035        1.601747      2.764076    6   \n",
       "3     1.1750    0.8875  0.2500  13.480187        2.282135      5.244657   10   \n",
       "4     0.8875    0.6625  0.2125   6.903103        1.488349      1.700970    6   \n",
       "...      ...       ...     ...        ...             ...           ...  ...   \n",
       "3847  1.4625    1.1375  0.3250  24.819987        5.854172      6.378637    8   \n",
       "3848  1.5500    1.2125  0.4375  34.458817        7.172423      9.780577   10   \n",
       "3849  0.6250    0.4625  0.1625   2.012815        0.524466      0.637864    5   \n",
       "3850  1.0625    0.7750  0.2625  10.347568        2.338834      2.976698    6   \n",
       "3851  0.7875    0.6125  0.2125   4.068153        1.346601      1.417475    8   \n",
       "\n",
       "      Sex_F  Sex_I  Sex_M  \n",
       "0         1      0      0  \n",
       "1         0      0      1  \n",
       "2         0      1      0  \n",
       "3         1      0      0  \n",
       "4         0      1      0  \n",
       "...     ...    ...    ...  \n",
       "3847      1      0      0  \n",
       "3848      1      0      0  \n",
       "3849      0      1      0  \n",
       "3850      0      1      0  \n",
       "3851      0      1      0  \n",
       "\n",
       "[3852 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c66ea07",
   "metadata": {},
   "source": [
    "### 3. 딥러닝을 위해 독립변수(x)와 종속변수(y)로 데이터 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f24d7df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#종속변수 \n",
    "df_y = df['Age'].values\n",
    "#독립변수\n",
    "df_x = df.drop(['Age'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "823de38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4375, 1.175 , 0.4125, ..., 1.    , 0.    , 0.    ],\n",
       "       [0.8875, 0.65  , 0.2125, ..., 0.    , 0.    , 1.    ],\n",
       "       [1.0375, 0.775 , 0.25  , ..., 0.    , 1.    , 0.    ],\n",
       "       ...,\n",
       "       [0.625 , 0.4625, 0.1625, ..., 0.    , 1.    , 0.    ],\n",
       "       [1.0625, 0.775 , 0.2625, ..., 0.    , 1.    , 0.    ],\n",
       "       [0.7875, 0.6125, 0.2125, ..., 0.    , 1.    , 0.    ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dce7a6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 6, 6, ..., 5, 6, 8], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe4963e",
   "metadata": {},
   "source": [
    "### 4.  K-겹 교차 검증(K-fold Cross Validation)을 사용한 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4a616f",
   "metadata": {},
   "source": [
    "sklearn에서 제공하는 StratifiedKFold 함수를 사용해 K-겹 교차 검증을 한다.  \n",
    "StratifiedKFold 함수의 옵션 중에서 n_splits 부분은 K-겹에서 K에 해당하는 값이다.  \n",
    "본 소스 코드에서는 5로 설정하여 5개의 그룹으로 데이터셋을 나누어 보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fba8f79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# seed 값 설정\n",
    "seed = 2\n",
    "\n",
    "# k 값 설정\n",
    "n_fold = 5\n",
    "skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7f5bbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedKFold(n_splits=5, random_state=2, shuffle=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6beb05",
   "metadata": {},
   "source": [
    "X(독립변수)와 Y(종속변수)의 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "811a2194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> X의 개수 :  3852\n",
      "[[1.4375 1.175  0.4125 ... 1.     0.     0.    ]\n",
      " [0.8875 0.65   0.2125 ... 0.     0.     1.    ]\n",
      " [1.0375 0.775  0.25   ... 0.     1.     0.    ]\n",
      " ...\n",
      " [0.625  0.4625 0.1625 ... 0.     1.     0.    ]\n",
      " [1.0625 0.775  0.2625 ... 0.     1.     0.    ]\n",
      " [0.7875 0.6125 0.2125 ... 0.     1.     0.    ]]\n",
      "\n",
      "-> Y의 개수 :  3852\n",
      "[9 6 6 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "print(\"-> X의 개수 : \", len(df_x))\n",
    "print(df_x)\n",
    "\n",
    "print(\"\\n-> Y의 개수 : \", len(df_y))\n",
    "print(df_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f974ea",
   "metadata": {},
   "source": [
    "학습 데이터 개수와 테스트 데이터 개수 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b4f5f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 개수 :  3852\n",
      "각 데이터셋의 개수 :  770\n",
      "학습 데이터 개수 :  3082\n",
      "테스트 데이터 개수 :  770\n"
     ]
    }
   ],
   "source": [
    "print(\"전체 데이터 개수 : \", len(df_x))\n",
    "\n",
    "# 전체 데이터개수를 k에 해당하는 5로 나누고 반올림\n",
    "print(\"각 데이터셋의 개수 : \", round(len(df_x)/5) )\n",
    "\n",
    "# 학습 데이터의 개수  \n",
    "print(\"학습 데이터 개수 : \", round(len(df_x)/5 * 4) )\n",
    "\n",
    "# 테스트 데이터의 개수  \n",
    "print(\"테스트 데이터 개수 : \", (len(df_x)- round(len(df_x)/5 * 4)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c092881",
   "metadata": {},
   "source": [
    "### 5. 딥러닝 모델 설계, 컴파일 및 실행하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8004bdf6",
   "metadata": {},
   "source": [
    "MAE를 한 번 시행할 때마다 저장하여 한꺼번에 보여줄 수 있게 mae 리스트를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42c71ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = []\n",
    "loss = []\n",
    "stage = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0ecdf7",
   "metadata": {},
   "source": [
    "아래의 for문은 n_fold만큼 반복된다.  \n",
    "데이터셋을 skf.split(df_x, df_y)를 이용해 학습 데이터셋과 테스트 데이터셋으로 나눈 후, 각각 train과 test에 할당한다.  \n",
    "n_fold 마다 셔플이 적용되어 학습 데이터셋과 테스트 데이터셋이 교차될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf1465e",
   "metadata": {},
   "source": [
    "df_x, df_y는 각각 3852개의 데이터가 있는 상태이며 skf로 셋팅된 환경으로 train, test로 shuffle되어 split된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c02b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8eff701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============  training 데이터 개수 :  3081 , test 데이터 개수 :  771 ==============\n",
      "-> K = 5 : 1 번째 그룹에 있는 test 데이터셋 사용 \n",
      "Epoch 1/50\n",
      "309/309 - 0s - loss: 16.4913 - mae: 3.2607 - val_loss: 12.2444 - val_mae: 2.6952\n",
      "Epoch 2/50\n",
      "309/309 - 0s - loss: 9.3964 - mae: 2.2794 - val_loss: 7.9141 - val_mae: 1.9489\n",
      "Epoch 3/50\n",
      "309/309 - 0s - loss: 6.7449 - mae: 1.8937 - val_loss: 6.3919 - val_mae: 1.8838\n",
      "Epoch 4/50\n",
      "309/309 - 0s - loss: 5.9806 - mae: 1.7821 - val_loss: 5.9706 - val_mae: 1.7146\n",
      "Epoch 5/50\n",
      "309/309 - 0s - loss: 5.7239 - mae: 1.7396 - val_loss: 5.6273 - val_mae: 1.7005\n",
      "Epoch 6/50\n",
      "309/309 - 0s - loss: 5.5505 - mae: 1.7068 - val_loss: 5.9478 - val_mae: 1.6547\n",
      "Epoch 7/50\n",
      "309/309 - 0s - loss: 5.4660 - mae: 1.6909 - val_loss: 5.4739 - val_mae: 1.6554\n",
      "Epoch 8/50\n",
      "309/309 - 0s - loss: 5.5240 - mae: 1.6930 - val_loss: 5.5135 - val_mae: 1.6329\n",
      "Epoch 9/50\n",
      "309/309 - 0s - loss: 5.4789 - mae: 1.6947 - val_loss: 5.4526 - val_mae: 1.6337\n",
      "Epoch 10/50\n",
      "309/309 - 0s - loss: 5.4078 - mae: 1.6770 - val_loss: 5.5963 - val_mae: 1.6174\n",
      "Epoch 11/50\n",
      "309/309 - 0s - loss: 5.4055 - mae: 1.6696 - val_loss: 5.4581 - val_mae: 1.6394\n",
      "Epoch 12/50\n",
      "309/309 - 0s - loss: 5.3229 - mae: 1.6560 - val_loss: 5.3740 - val_mae: 1.6216\n",
      "Epoch 13/50\n",
      "309/309 - 0s - loss: 5.3045 - mae: 1.6546 - val_loss: 5.7721 - val_mae: 1.6113\n",
      "Epoch 14/50\n",
      "309/309 - 0s - loss: 5.3699 - mae: 1.6523 - val_loss: 5.2937 - val_mae: 1.6161\n",
      "Epoch 15/50\n",
      "309/309 - 0s - loss: 5.3115 - mae: 1.6441 - val_loss: 5.2741 - val_mae: 1.6450\n",
      "Epoch 16/50\n",
      "309/309 - 0s - loss: 5.2961 - mae: 1.6417 - val_loss: 5.4614 - val_mae: 1.5839\n",
      "Epoch 17/50\n",
      "309/309 - 0s - loss: 5.3443 - mae: 1.6489 - val_loss: 5.2315 - val_mae: 1.6007\n",
      "Epoch 18/50\n",
      "309/309 - 0s - loss: 5.3046 - mae: 1.6501 - val_loss: 5.7078 - val_mae: 1.5948\n",
      "Epoch 19/50\n",
      "309/309 - 0s - loss: 5.2791 - mae: 1.6376 - val_loss: 5.2253 - val_mae: 1.6289\n",
      "Epoch 20/50\n",
      "309/309 - 0s - loss: 5.2233 - mae: 1.6451 - val_loss: 5.4649 - val_mae: 1.5729\n",
      "Epoch 21/50\n",
      "309/309 - 0s - loss: 5.2752 - mae: 1.6315 - val_loss: 5.2201 - val_mae: 1.5753\n",
      "Epoch 22/50\n",
      "309/309 - 0s - loss: 5.2588 - mae: 1.6418 - val_loss: 5.3530 - val_mae: 1.5714\n",
      "Epoch 23/50\n",
      "309/309 - 0s - loss: 5.2302 - mae: 1.6306 - val_loss: 5.1252 - val_mae: 1.5840\n",
      "Epoch 24/50\n",
      "309/309 - 0s - loss: 5.2779 - mae: 1.6350 - val_loss: 5.4409 - val_mae: 1.7448\n",
      "Epoch 25/50\n",
      "309/309 - 0s - loss: 5.2197 - mae: 1.6243 - val_loss: 5.2670 - val_mae: 1.5613\n",
      "Epoch 26/50\n",
      "309/309 - 0s - loss: 5.2115 - mae: 1.6220 - val_loss: 5.0877 - val_mae: 1.5743\n",
      "Epoch 27/50\n",
      "309/309 - 0s - loss: 5.1996 - mae: 1.6201 - val_loss: 5.0978 - val_mae: 1.6088\n",
      "Epoch 28/50\n",
      "309/309 - 0s - loss: 5.2002 - mae: 1.6258 - val_loss: 5.1857 - val_mae: 1.6377\n",
      "Epoch 29/50\n",
      "309/309 - 0s - loss: 5.2489 - mae: 1.6311 - val_loss: 5.0739 - val_mae: 1.5974\n",
      "Epoch 30/50\n",
      "309/309 - 0s - loss: 5.1927 - mae: 1.6164 - val_loss: 5.1106 - val_mae: 1.5751\n",
      "Epoch 31/50\n",
      "309/309 - 0s - loss: 5.1965 - mae: 1.6118 - val_loss: 5.2191 - val_mae: 1.6367\n",
      "Epoch 32/50\n",
      "309/309 - 0s - loss: 5.2012 - mae: 1.6237 - val_loss: 5.0451 - val_mae: 1.5975\n",
      "Epoch 33/50\n",
      "309/309 - 0s - loss: 5.1650 - mae: 1.6180 - val_loss: 5.1194 - val_mae: 1.5516\n",
      "Epoch 34/50\n",
      "309/309 - 0s - loss: 5.1419 - mae: 1.6027 - val_loss: 5.2018 - val_mae: 1.6110\n",
      "Epoch 35/50\n",
      "309/309 - 0s - loss: 5.1191 - mae: 1.6151 - val_loss: 5.1236 - val_mae: 1.5488\n",
      "Epoch 36/50\n",
      "309/309 - 0s - loss: 5.1743 - mae: 1.6145 - val_loss: 5.0596 - val_mae: 1.6162\n",
      "Epoch 37/50\n",
      "309/309 - 0s - loss: 5.2410 - mae: 1.6233 - val_loss: 5.9608 - val_mae: 1.6051\n",
      "Epoch 38/50\n",
      "309/309 - 0s - loss: 5.1711 - mae: 1.6132 - val_loss: 5.0775 - val_mae: 1.5684\n",
      "Epoch 39/50\n",
      "309/309 - 0s - loss: 5.2546 - mae: 1.6329 - val_loss: 5.1050 - val_mae: 1.5526\n",
      "Epoch 40/50\n",
      "309/309 - 0s - loss: 5.1507 - mae: 1.6063 - val_loss: 5.1932 - val_mae: 1.6797\n",
      "Epoch 41/50\n",
      "309/309 - 0s - loss: 5.1731 - mae: 1.6133 - val_loss: 5.0429 - val_mae: 1.5932\n",
      "Epoch 42/50\n",
      "309/309 - 0s - loss: 5.2513 - mae: 1.6253 - val_loss: 5.1230 - val_mae: 1.5655\n",
      "Epoch 43/50\n",
      "309/309 - 0s - loss: 5.1629 - mae: 1.6115 - val_loss: 5.0468 - val_mae: 1.5840\n",
      "Epoch 44/50\n",
      "309/309 - 0s - loss: 5.1434 - mae: 1.6131 - val_loss: 5.0265 - val_mae: 1.5623\n",
      "Epoch 45/50\n",
      "309/309 - 0s - loss: 5.1276 - mae: 1.6116 - val_loss: 5.0459 - val_mae: 1.5777\n",
      "Epoch 46/50\n",
      "309/309 - 0s - loss: 5.1154 - mae: 1.6125 - val_loss: 5.0866 - val_mae: 1.5543\n",
      "Epoch 47/50\n",
      "309/309 - 0s - loss: 5.1630 - mae: 1.6118 - val_loss: 5.0150 - val_mae: 1.5947\n",
      "Epoch 48/50\n",
      "309/309 - 0s - loss: 5.1594 - mae: 1.6052 - val_loss: 5.0040 - val_mae: 1.5915\n",
      "Epoch 49/50\n",
      "309/309 - 0s - loss: 5.1271 - mae: 1.6074 - val_loss: 5.0496 - val_mae: 1.5489\n",
      "Epoch 50/50\n",
      "309/309 - 0s - loss: 5.1450 - mae: 1.6081 - val_loss: 5.0233 - val_mae: 1.5549\n",
      "97/97 - 0s - loss: 5.0358 - mae: 1.5784\n",
      "-> Test dataset evaluation : Loss = 5.0358\n",
      "-> Test dataset evaluation : MAE = 1.5784\n",
      "==============  training 데이터 개수 :  3081 , test 데이터 개수 :  771 ==============\n",
      "-> K = 5 : 2 번째 그룹에 있는 test 데이터셋 사용 \n",
      "Epoch 1/50\n",
      "309/309 - 0s - loss: 20.9432 - mae: 3.5998 - val_loss: 10.1158 - val_mae: 2.3999\n",
      "Epoch 2/50\n",
      "309/309 - 0s - loss: 7.0750 - mae: 1.8999 - val_loss: 5.7768 - val_mae: 1.7192\n",
      "Epoch 3/50\n",
      "309/309 - 0s - loss: 5.8101 - mae: 1.7087 - val_loss: 5.4334 - val_mae: 1.7447\n",
      "Epoch 4/50\n",
      "309/309 - 0s - loss: 5.5110 - mae: 1.6664 - val_loss: 5.2751 - val_mae: 1.6292\n",
      "Epoch 5/50\n",
      "309/309 - 0s - loss: 5.4211 - mae: 1.6521 - val_loss: 5.5042 - val_mae: 1.5995\n",
      "Epoch 6/50\n",
      "309/309 - 0s - loss: 5.3870 - mae: 1.6468 - val_loss: 5.2140 - val_mae: 1.6600\n",
      "Epoch 7/50\n",
      "309/309 - 0s - loss: 5.4069 - mae: 1.6591 - val_loss: 5.1699 - val_mae: 1.6601\n",
      "Epoch 8/50\n",
      "309/309 - 0s - loss: 5.3491 - mae: 1.6449 - val_loss: 5.2541 - val_mae: 1.5979\n",
      "Epoch 9/50\n",
      "309/309 - 0s - loss: 5.3023 - mae: 1.6435 - val_loss: 5.3101 - val_mae: 1.5902\n",
      "Epoch 10/50\n",
      "309/309 - 0s - loss: 5.2453 - mae: 1.6272 - val_loss: 5.3517 - val_mae: 1.7455\n",
      "Epoch 11/50\n",
      "309/309 - 0s - loss: 5.3297 - mae: 1.6443 - val_loss: 5.1804 - val_mae: 1.5998\n",
      "Epoch 12/50\n",
      "309/309 - 0s - loss: 5.2828 - mae: 1.6357 - val_loss: 5.2924 - val_mae: 1.7225\n",
      "Epoch 13/50\n",
      "309/309 - 0s - loss: 5.2685 - mae: 1.6436 - val_loss: 5.5483 - val_mae: 1.5929\n",
      "Epoch 14/50\n",
      "309/309 - 0s - loss: 5.2381 - mae: 1.6257 - val_loss: 5.1907 - val_mae: 1.5960\n",
      "Epoch 15/50\n",
      "309/309 - 0s - loss: 5.2411 - mae: 1.6380 - val_loss: 5.2341 - val_mae: 1.5852\n",
      "Epoch 16/50\n",
      "309/309 - 0s - loss: 5.2342 - mae: 1.6316 - val_loss: 5.1594 - val_mae: 1.6640\n",
      "Epoch 17/50\n",
      "309/309 - 0s - loss: 5.2361 - mae: 1.6324 - val_loss: 5.2525 - val_mae: 1.7068\n",
      "Epoch 18/50\n",
      "309/309 - 0s - loss: 5.3221 - mae: 1.6480 - val_loss: 5.1658 - val_mae: 1.6728\n",
      "Epoch 19/50\n",
      "309/309 - 0s - loss: 5.2566 - mae: 1.6402 - val_loss: 5.2472 - val_mae: 1.5811\n",
      "Epoch 20/50\n",
      "309/309 - 0s - loss: 5.2478 - mae: 1.6331 - val_loss: 5.1833 - val_mae: 1.6090\n",
      "Epoch 21/50\n",
      "309/309 - 0s - loss: 5.2387 - mae: 1.6284 - val_loss: 5.1056 - val_mae: 1.6378\n",
      "Epoch 22/50\n",
      "309/309 - 0s - loss: 5.2299 - mae: 1.6316 - val_loss: 5.1710 - val_mae: 1.6391\n",
      "Epoch 23/50\n",
      "309/309 - 0s - loss: 5.2109 - mae: 1.6245 - val_loss: 5.3456 - val_mae: 1.7370\n",
      "Epoch 24/50\n",
      "309/309 - 0s - loss: 5.2226 - mae: 1.6260 - val_loss: 5.2949 - val_mae: 1.5920\n",
      "Epoch 25/50\n",
      "309/309 - 0s - loss: 5.1850 - mae: 1.6205 - val_loss: 5.0916 - val_mae: 1.6123\n",
      "Epoch 26/50\n",
      "309/309 - 0s - loss: 5.1619 - mae: 1.6105 - val_loss: 5.1553 - val_mae: 1.6452\n",
      "Epoch 27/50\n",
      "309/309 - 0s - loss: 5.2214 - mae: 1.6349 - val_loss: 5.1403 - val_mae: 1.5801\n",
      "Epoch 28/50\n",
      "309/309 - 0s - loss: 5.1671 - mae: 1.6236 - val_loss: 5.1554 - val_mae: 1.5794\n",
      "Epoch 29/50\n",
      "309/309 - 0s - loss: 5.1311 - mae: 1.6168 - val_loss: 5.1707 - val_mae: 1.6681\n",
      "Epoch 30/50\n",
      "309/309 - 0s - loss: 5.1596 - mae: 1.6184 - val_loss: 5.0920 - val_mae: 1.6097\n",
      "Epoch 31/50\n",
      "309/309 - 0s - loss: 5.1806 - mae: 1.6178 - val_loss: 5.1025 - val_mae: 1.6046\n",
      "Epoch 32/50\n",
      "309/309 - 0s - loss: 5.1148 - mae: 1.6060 - val_loss: 5.0624 - val_mae: 1.6209\n",
      "Epoch 33/50\n",
      "309/309 - 0s - loss: 5.1295 - mae: 1.6113 - val_loss: 5.2226 - val_mae: 1.5822\n",
      "Epoch 34/50\n",
      "309/309 - 0s - loss: 5.0595 - mae: 1.5990 - val_loss: 5.1035 - val_mae: 1.6089\n",
      "Epoch 35/50\n",
      "309/309 - 0s - loss: 5.0649 - mae: 1.6033 - val_loss: 5.1050 - val_mae: 1.6381\n",
      "Epoch 36/50\n",
      "309/309 - 0s - loss: 5.1048 - mae: 1.6109 - val_loss: 5.1545 - val_mae: 1.5880\n",
      "Epoch 37/50\n",
      "309/309 - 0s - loss: 5.0602 - mae: 1.6028 - val_loss: 5.3609 - val_mae: 1.5706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "309/309 - 0s - loss: 5.0985 - mae: 1.5949 - val_loss: 5.1671 - val_mae: 1.6462\n",
      "Epoch 39/50\n",
      "309/309 - 0s - loss: 5.0472 - mae: 1.6009 - val_loss: 5.0811 - val_mae: 1.6039\n",
      "Epoch 40/50\n",
      "309/309 - 0s - loss: 5.0585 - mae: 1.5973 - val_loss: 5.2385 - val_mae: 1.5715\n",
      "Epoch 41/50\n",
      "309/309 - 0s - loss: 5.0173 - mae: 1.5891 - val_loss: 5.1889 - val_mae: 1.6818\n",
      "Epoch 42/50\n",
      "309/309 - 0s - loss: 5.1224 - mae: 1.6103 - val_loss: 5.2417 - val_mae: 1.7048\n",
      "Epoch 43/50\n",
      "309/309 - 0s - loss: 5.0181 - mae: 1.5911 - val_loss: 5.5800 - val_mae: 1.8110\n",
      "Epoch 44/50\n",
      "309/309 - 0s - loss: 5.0263 - mae: 1.5940 - val_loss: 5.3224 - val_mae: 1.5814\n",
      "Epoch 45/50\n",
      "309/309 - 0s - loss: 5.0404 - mae: 1.5954 - val_loss: 5.2834 - val_mae: 1.5755\n",
      "Epoch 46/50\n",
      "309/309 - 0s - loss: 5.0470 - mae: 1.5999 - val_loss: 5.0713 - val_mae: 1.6131\n",
      "Epoch 47/50\n",
      "309/309 - 0s - loss: 5.0265 - mae: 1.5908 - val_loss: 5.1586 - val_mae: 1.5690\n",
      "Epoch 48/50\n",
      "309/309 - 0s - loss: 5.0073 - mae: 1.5767 - val_loss: 5.5100 - val_mae: 1.8099\n",
      "Epoch 49/50\n",
      "309/309 - 0s - loss: 5.0618 - mae: 1.5966 - val_loss: 5.3304 - val_mae: 1.7277\n",
      "Epoch 50/50\n",
      "309/309 - 0s - loss: 5.0102 - mae: 1.5936 - val_loss: 5.2095 - val_mae: 1.6781\n",
      "97/97 - 0s - loss: 4.9947 - mae: 1.6452\n",
      "-> Test dataset evaluation : Loss = 4.9947\n",
      "-> Test dataset evaluation : MAE = 1.6452\n",
      "==============  training 데이터 개수 :  3082 , test 데이터 개수 :  770 ==============\n",
      "-> K = 5 : 3 번째 그룹에 있는 test 데이터셋 사용 \n",
      "Epoch 1/50\n",
      "309/309 - 0s - loss: 18.9563 - mae: 3.3599 - val_loss: 7.3375 - val_mae: 2.0293\n",
      "Epoch 2/50\n",
      "309/309 - 0s - loss: 6.5294 - mae: 1.8397 - val_loss: 5.3774 - val_mae: 1.6134\n",
      "Epoch 3/50\n",
      "309/309 - 0s - loss: 5.7464 - mae: 1.7209 - val_loss: 5.4092 - val_mae: 1.5331\n",
      "Epoch 4/50\n",
      "309/309 - 0s - loss: 5.5346 - mae: 1.6895 - val_loss: 5.5354 - val_mae: 1.5371\n",
      "Epoch 5/50\n",
      "309/309 - 0s - loss: 5.5046 - mae: 1.6800 - val_loss: 4.9832 - val_mae: 1.5093\n",
      "Epoch 6/50\n",
      "309/309 - 0s - loss: 5.4679 - mae: 1.6766 - val_loss: 4.9158 - val_mae: 1.5118\n",
      "Epoch 7/50\n",
      "309/309 - 0s - loss: 5.4754 - mae: 1.6751 - val_loss: 4.8084 - val_mae: 1.5759\n",
      "Epoch 8/50\n",
      "309/309 - 0s - loss: 5.4427 - mae: 1.6660 - val_loss: 4.8190 - val_mae: 1.6081\n",
      "Epoch 9/50\n",
      "309/309 - 0s - loss: 5.5011 - mae: 1.6746 - val_loss: 4.7977 - val_mae: 1.5170\n",
      "Epoch 10/50\n",
      "309/309 - 0s - loss: 5.4538 - mae: 1.6695 - val_loss: 4.8759 - val_mae: 1.6289\n",
      "Epoch 11/50\n",
      "309/309 - 0s - loss: 5.4229 - mae: 1.6638 - val_loss: 4.8311 - val_mae: 1.4985\n",
      "Epoch 12/50\n",
      "309/309 - 0s - loss: 5.3892 - mae: 1.6612 - val_loss: 5.0354 - val_mae: 1.4980\n",
      "Epoch 13/50\n",
      "309/309 - 0s - loss: 5.3897 - mae: 1.6610 - val_loss: 4.7792 - val_mae: 1.6085\n",
      "Epoch 14/50\n",
      "309/309 - 0s - loss: 5.4124 - mae: 1.6596 - val_loss: 4.7079 - val_mae: 1.5477\n",
      "Epoch 15/50\n",
      "309/309 - 0s - loss: 5.3631 - mae: 1.6508 - val_loss: 5.1170 - val_mae: 1.4966\n",
      "Epoch 16/50\n",
      "309/309 - 0s - loss: 5.3723 - mae: 1.6439 - val_loss: 4.7311 - val_mae: 1.5164\n",
      "Epoch 17/50\n",
      "309/309 - 0s - loss: 5.3913 - mae: 1.6437 - val_loss: 4.7415 - val_mae: 1.5989\n",
      "Epoch 18/50\n",
      "309/309 - 0s - loss: 5.3615 - mae: 1.6428 - val_loss: 4.7374 - val_mae: 1.6109\n",
      "Epoch 19/50\n",
      "309/309 - 0s - loss: 5.3285 - mae: 1.6416 - val_loss: 4.6591 - val_mae: 1.5253\n",
      "Epoch 20/50\n",
      "309/309 - 0s - loss: 5.2994 - mae: 1.6240 - val_loss: 4.7174 - val_mae: 1.5111\n",
      "Epoch 21/50\n",
      "309/309 - 0s - loss: 5.3117 - mae: 1.6403 - val_loss: 4.7729 - val_mae: 1.6177\n",
      "Epoch 22/50\n",
      "309/309 - 0s - loss: 5.2982 - mae: 1.6350 - val_loss: 4.7173 - val_mae: 1.4923\n",
      "Epoch 23/50\n",
      "309/309 - 0s - loss: 5.4124 - mae: 1.6471 - val_loss: 4.6779 - val_mae: 1.5731\n",
      "Epoch 24/50\n",
      "309/309 - 0s - loss: 5.3236 - mae: 1.6277 - val_loss: 4.9615 - val_mae: 1.7108\n",
      "Epoch 25/50\n",
      "309/309 - 0s - loss: 5.2912 - mae: 1.6303 - val_loss: 4.6462 - val_mae: 1.5455\n",
      "Epoch 26/50\n",
      "309/309 - 0s - loss: 5.3516 - mae: 1.6368 - val_loss: 4.6656 - val_mae: 1.5090\n",
      "Epoch 27/50\n",
      "309/309 - 0s - loss: 5.2900 - mae: 1.6349 - val_loss: 4.9481 - val_mae: 1.4780\n",
      "Epoch 28/50\n",
      "309/309 - 0s - loss: 5.2828 - mae: 1.6221 - val_loss: 4.8068 - val_mae: 1.6526\n",
      "Epoch 29/50\n",
      "309/309 - 0s - loss: 5.2833 - mae: 1.6279 - val_loss: 4.6619 - val_mae: 1.5519\n",
      "Epoch 30/50\n",
      "309/309 - 0s - loss: 5.2498 - mae: 1.6317 - val_loss: 4.6514 - val_mae: 1.4911\n",
      "Epoch 31/50\n",
      "309/309 - 0s - loss: 5.2844 - mae: 1.6269 - val_loss: 4.8359 - val_mae: 1.4751\n",
      "Epoch 32/50\n",
      "309/309 - 0s - loss: 5.2545 - mae: 1.6178 - val_loss: 4.6540 - val_mae: 1.5001\n",
      "Epoch 33/50\n",
      "309/309 - 0s - loss: 5.2078 - mae: 1.6254 - val_loss: 4.7055 - val_mae: 1.6072\n",
      "Epoch 34/50\n",
      "309/309 - 0s - loss: 5.1915 - mae: 1.6225 - val_loss: 4.9522 - val_mae: 1.4758\n",
      "Epoch 35/50\n",
      "309/309 - 0s - loss: 5.2769 - mae: 1.6290 - val_loss: 4.6980 - val_mae: 1.4839\n",
      "Epoch 36/50\n",
      "309/309 - 0s - loss: 5.2059 - mae: 1.6198 - val_loss: 5.0433 - val_mae: 1.4779\n",
      "Epoch 37/50\n",
      "309/309 - 0s - loss: 5.2481 - mae: 1.6239 - val_loss: 4.9790 - val_mae: 1.4854\n",
      "Epoch 38/50\n",
      "309/309 - 0s - loss: 5.1906 - mae: 1.6148 - val_loss: 4.8892 - val_mae: 1.4863\n",
      "Epoch 39/50\n",
      "309/309 - 0s - loss: 5.2629 - mae: 1.6274 - val_loss: 4.6599 - val_mae: 1.5745\n",
      "Epoch 40/50\n",
      "309/309 - 0s - loss: 5.1979 - mae: 1.6080 - val_loss: 4.6550 - val_mae: 1.5033\n",
      "Epoch 41/50\n",
      "309/309 - 0s - loss: 5.2351 - mae: 1.6187 - val_loss: 4.6364 - val_mae: 1.5065\n",
      "Epoch 42/50\n",
      "309/309 - 0s - loss: 5.2080 - mae: 1.6172 - val_loss: 4.8333 - val_mae: 1.4847\n",
      "Epoch 43/50\n",
      "309/309 - 0s - loss: 5.2058 - mae: 1.6155 - val_loss: 4.7028 - val_mae: 1.6179\n",
      "Epoch 44/50\n",
      "309/309 - 0s - loss: 5.1632 - mae: 1.6161 - val_loss: 4.7343 - val_mae: 1.5075\n",
      "Epoch 45/50\n",
      "309/309 - 0s - loss: 5.1578 - mae: 1.6090 - val_loss: 4.7262 - val_mae: 1.4855\n",
      "Epoch 46/50\n",
      "309/309 - 0s - loss: 5.2361 - mae: 1.6188 - val_loss: 4.8072 - val_mae: 1.6499\n",
      "Epoch 47/50\n",
      "309/309 - 0s - loss: 5.2247 - mae: 1.6230 - val_loss: 4.7401 - val_mae: 1.4686\n",
      "Epoch 48/50\n",
      "309/309 - 0s - loss: 5.1660 - mae: 1.6179 - val_loss: 4.7322 - val_mae: 1.4907\n",
      "Epoch 49/50\n",
      "309/309 - 0s - loss: 5.1771 - mae: 1.6095 - val_loss: 4.6014 - val_mae: 1.5497\n",
      "Epoch 50/50\n",
      "309/309 - 0s - loss: 5.1832 - mae: 1.6130 - val_loss: 4.6008 - val_mae: 1.5608\n",
      "97/97 - 0s - loss: 5.1179 - mae: 1.6377\n",
      "-> Test dataset evaluation : Loss = 5.1179\n",
      "-> Test dataset evaluation : MAE = 1.6377\n",
      "==============  training 데이터 개수 :  3082 , test 데이터 개수 :  770 ==============\n",
      "-> K = 5 : 4 번째 그룹에 있는 test 데이터셋 사용 \n",
      "Epoch 1/50\n",
      "309/309 - 0s - loss: 183.9279 - mae: 12.2765 - val_loss: 105.0097 - val_mae: 9.7390\n",
      "Epoch 2/50\n",
      "309/309 - 0s - loss: 102.1300 - mae: 9.5912 - val_loss: 100.0257 - val_mae: 9.4811\n",
      "Epoch 3/50\n",
      "309/309 - 0s - loss: 97.1037 - mae: 9.3247 - val_loss: 94.9396 - val_mae: 9.2091\n",
      "Epoch 4/50\n",
      "309/309 - 0s - loss: 92.0412 - mae: 9.0497 - val_loss: 89.9037 - val_mae: 8.9315\n",
      "Epoch 5/50\n",
      "309/309 - 0s - loss: 87.0647 - mae: 8.7704 - val_loss: 84.9699 - val_mae: 8.6509\n",
      "Epoch 6/50\n",
      "309/309 - 0s - loss: 82.2278 - mae: 8.4910 - val_loss: 80.2063 - val_mae: 8.3710\n",
      "Epoch 7/50\n",
      "309/309 - 0s - loss: 77.5483 - mae: 8.2108 - val_loss: 75.5993 - val_mae: 8.0912\n",
      "Epoch 8/50\n",
      "309/309 - 0s - loss: 73.0487 - mae: 7.9310 - val_loss: 71.1802 - val_mae: 7.8133\n",
      "Epoch 9/50\n",
      "309/309 - 0s - loss: 68.7205 - mae: 7.6538 - val_loss: 66.9242 - val_mae: 7.5360\n",
      "Epoch 10/50\n",
      "309/309 - 0s - loss: 64.5705 - mae: 7.3773 - val_loss: 62.8513 - val_mae: 7.2608\n",
      "Epoch 11/50\n",
      "309/309 - 0s - loss: 60.5955 - mae: 7.1038 - val_loss: 58.9555 - val_mae: 6.9874\n",
      "Epoch 12/50\n",
      "309/309 - 0s - loss: 56.7866 - mae: 6.8319 - val_loss: 55.2197 - val_mae: 6.7160\n",
      "Epoch 13/50\n",
      "309/309 - 0s - loss: 53.1529 - mae: 6.5619 - val_loss: 51.6581 - val_mae: 6.4467\n",
      "Epoch 14/50\n",
      "309/309 - 0s - loss: 49.6918 - mae: 6.2934 - val_loss: 48.2745 - val_mae: 6.1800\n",
      "Epoch 15/50\n",
      "309/309 - 0s - loss: 46.4024 - mae: 6.0291 - val_loss: 45.0495 - val_mae: 5.9163\n",
      "Epoch 16/50\n",
      "309/309 - 0s - loss: 43.2778 - mae: 5.7706 - val_loss: 42.0006 - val_mae: 5.6606\n",
      "Epoch 17/50\n",
      "309/309 - 0s - loss: 40.3130 - mae: 5.5167 - val_loss: 39.1087 - val_mae: 5.4065\n",
      "Epoch 18/50\n",
      "309/309 - 0s - loss: 37.5124 - mae: 5.2630 - val_loss: 36.3762 - val_mae: 5.1546\n",
      "Epoch 19/50\n",
      "309/309 - 0s - loss: 34.8669 - mae: 5.0153 - val_loss: 33.7970 - val_mae: 4.9104\n",
      "Epoch 20/50\n",
      "309/309 - 0s - loss: 32.3678 - mae: 4.7795 - val_loss: 31.3659 - val_mae: 4.6757\n",
      "Epoch 21/50\n",
      "309/309 - 0s - loss: 30.0361 - mae: 4.5473 - val_loss: 29.1001 - val_mae: 4.4446\n",
      "Epoch 22/50\n",
      "309/309 - 0s - loss: 27.8585 - mae: 4.3166 - val_loss: 26.9949 - val_mae: 4.2171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "309/309 - 0s - loss: 25.8234 - mae: 4.0948 - val_loss: 25.0184 - val_mae: 4.0046\n",
      "Epoch 24/50\n",
      "309/309 - 0s - loss: 23.9390 - mae: 3.8966 - val_loss: 23.1951 - val_mae: 3.8113\n",
      "Epoch 25/50\n",
      "309/309 - 0s - loss: 22.1962 - mae: 3.7051 - val_loss: 21.5128 - val_mae: 3.6205\n",
      "Epoch 26/50\n",
      "309/309 - 0s - loss: 20.5973 - mae: 3.5159 - val_loss: 19.9683 - val_mae: 3.4326\n",
      "Epoch 27/50\n",
      "309/309 - 0s - loss: 19.0935 - mae: 3.3224 - val_loss: 18.4371 - val_mae: 3.2318\n",
      "Epoch 28/50\n",
      "309/309 - 0s - loss: 17.5470 - mae: 3.1124 - val_loss: 17.0321 - val_mae: 3.0499\n",
      "Epoch 29/50\n",
      "309/309 - 0s - loss: 16.2110 - mae: 2.9415 - val_loss: 15.8170 - val_mae: 2.8979\n",
      "Epoch 30/50\n",
      "309/309 - 0s - loss: 15.0110 - mae: 2.7787 - val_loss: 14.6394 - val_mae: 2.7331\n",
      "Epoch 31/50\n",
      "309/309 - 0s - loss: 13.9241 - mae: 2.6188 - val_loss: 13.6256 - val_mae: 2.5746\n",
      "Epoch 32/50\n",
      "309/309 - 0s - loss: 12.9355 - mae: 2.4841 - val_loss: 12.6687 - val_mae: 2.4610\n",
      "Epoch 33/50\n",
      "309/309 - 0s - loss: 12.0471 - mae: 2.3761 - val_loss: 11.8254 - val_mae: 2.3665\n",
      "Epoch 34/50\n",
      "309/309 - 0s - loss: 11.2460 - mae: 2.2710 - val_loss: 11.0717 - val_mae: 2.2507\n",
      "Epoch 35/50\n",
      "309/309 - 0s - loss: 10.5239 - mae: 2.1617 - val_loss: 10.4624 - val_mae: 2.1516\n",
      "Epoch 36/50\n",
      "309/309 - 0s - loss: 9.8873 - mae: 2.0625 - val_loss: 9.8059 - val_mae: 2.0476\n",
      "Epoch 37/50\n",
      "309/309 - 0s - loss: 9.3229 - mae: 1.9945 - val_loss: 9.2704 - val_mae: 2.0130\n",
      "Epoch 38/50\n",
      "309/309 - 0s - loss: 8.8262 - mae: 1.9481 - val_loss: 8.8349 - val_mae: 1.9479\n",
      "Epoch 39/50\n",
      "309/309 - 0s - loss: 8.3930 - mae: 1.9022 - val_loss: 8.4277 - val_mae: 1.9267\n",
      "Epoch 40/50\n",
      "309/309 - 0s - loss: 8.0228 - mae: 1.8556 - val_loss: 8.0792 - val_mae: 1.8525\n",
      "Epoch 41/50\n",
      "309/309 - 0s - loss: 7.7111 - mae: 1.8140 - val_loss: 7.7818 - val_mae: 1.8199\n",
      "Epoch 42/50\n",
      "309/309 - 0s - loss: 7.3987 - mae: 1.7672 - val_loss: 7.4403 - val_mae: 1.7556\n",
      "Epoch 43/50\n",
      "309/309 - 0s - loss: 7.1475 - mae: 1.7544 - val_loss: 7.2427 - val_mae: 1.7503\n",
      "Epoch 44/50\n",
      "309/309 - 0s - loss: 6.9228 - mae: 1.7435 - val_loss: 6.9917 - val_mae: 1.7306\n",
      "Epoch 45/50\n",
      "309/309 - 0s - loss: 6.7515 - mae: 1.7382 - val_loss: 6.8149 - val_mae: 1.7404\n",
      "Epoch 46/50\n",
      "309/309 - 0s - loss: 6.5734 - mae: 1.7141 - val_loss: 6.6638 - val_mae: 1.7315\n",
      "Epoch 47/50\n",
      "309/309 - 0s - loss: 6.4309 - mae: 1.6944 - val_loss: 6.5154 - val_mae: 1.7019\n",
      "Epoch 48/50\n",
      "309/309 - 0s - loss: 6.2819 - mae: 1.6777 - val_loss: 6.4834 - val_mae: 1.7479\n",
      "Epoch 49/50\n",
      "309/309 - 0s - loss: 6.1783 - mae: 1.6709 - val_loss: 6.3091 - val_mae: 1.6724\n",
      "Epoch 50/50\n",
      "309/309 - 0s - loss: 6.0648 - mae: 1.6644 - val_loss: 6.8432 - val_mae: 1.7170\n",
      "97/97 - 0s - loss: 6.3603 - mae: 1.6457\n",
      "-> Test dataset evaluation : Loss = 6.3603\n",
      "-> Test dataset evaluation : MAE = 1.6457\n",
      "==============  training 데이터 개수 :  3082 , test 데이터 개수 :  770 ==============\n",
      "-> K = 5 : 5 번째 그룹에 있는 test 데이터셋 사용 \n",
      "Epoch 1/50\n",
      "309/309 - 0s - loss: 36.3691 - mae: 4.8257 - val_loss: 12.0986 - val_mae: 2.6917\n",
      "Epoch 2/50\n",
      "309/309 - 0s - loss: 10.3085 - mae: 2.4426 - val_loss: 7.8681 - val_mae: 2.0211\n",
      "Epoch 3/50\n",
      "309/309 - 0s - loss: 6.9898 - mae: 1.8919 - val_loss: 6.3177 - val_mae: 1.7674\n",
      "Epoch 4/50\n",
      "309/309 - 0s - loss: 6.0483 - mae: 1.7705 - val_loss: 5.8850 - val_mae: 1.7812\n",
      "Epoch 5/50\n",
      "309/309 - 0s - loss: 5.7139 - mae: 1.7127 - val_loss: 5.7568 - val_mae: 1.8183\n",
      "Epoch 6/50\n",
      "309/309 - 0s - loss: 5.5487 - mae: 1.6885 - val_loss: 5.6112 - val_mae: 1.7860\n",
      "Epoch 7/50\n",
      "309/309 - 0s - loss: 5.4313 - mae: 1.6600 - val_loss: 5.5078 - val_mae: 1.7665\n",
      "Epoch 8/50\n",
      "309/309 - 0s - loss: 5.3510 - mae: 1.6478 - val_loss: 5.5526 - val_mae: 1.6088\n",
      "Epoch 9/50\n",
      "309/309 - 0s - loss: 5.2751 - mae: 1.6318 - val_loss: 5.4250 - val_mae: 1.7385\n",
      "Epoch 10/50\n",
      "309/309 - 0s - loss: 5.2590 - mae: 1.6297 - val_loss: 5.8438 - val_mae: 1.9049\n",
      "Epoch 11/50\n",
      "309/309 - 0s - loss: 5.2584 - mae: 1.6392 - val_loss: 5.9177 - val_mae: 1.9294\n",
      "Epoch 12/50\n",
      "309/309 - 0s - loss: 5.2091 - mae: 1.6263 - val_loss: 5.3341 - val_mae: 1.6449\n",
      "Epoch 13/50\n",
      "309/309 - 0s - loss: 5.2242 - mae: 1.6239 - val_loss: 5.7728 - val_mae: 1.8899\n",
      "Epoch 14/50\n",
      "309/309 - 0s - loss: 5.1962 - mae: 1.6286 - val_loss: 5.2984 - val_mae: 1.6219\n",
      "Epoch 15/50\n",
      "309/309 - 0s - loss: 5.2086 - mae: 1.6181 - val_loss: 5.3187 - val_mae: 1.6437\n",
      "Epoch 16/50\n",
      "309/309 - 0s - loss: 5.1658 - mae: 1.6151 - val_loss: 5.3241 - val_mae: 1.6955\n",
      "Epoch 17/50\n",
      "309/309 - 0s - loss: 5.1552 - mae: 1.6171 - val_loss: 5.3884 - val_mae: 1.6075\n",
      "Epoch 18/50\n",
      "309/309 - 0s - loss: 5.1865 - mae: 1.6189 - val_loss: 5.3236 - val_mae: 1.6929\n",
      "Epoch 19/50\n",
      "309/309 - 0s - loss: 5.1599 - mae: 1.6139 - val_loss: 5.3519 - val_mae: 1.6958\n",
      "Epoch 20/50\n",
      "309/309 - 0s - loss: 5.1975 - mae: 1.6192 - val_loss: 5.3258 - val_mae: 1.6036\n",
      "Epoch 21/50\n",
      "309/309 - 0s - loss: 5.2001 - mae: 1.6234 - val_loss: 5.2651 - val_mae: 1.6481\n",
      "Epoch 22/50\n",
      "309/309 - 0s - loss: 5.1563 - mae: 1.6070 - val_loss: 5.3140 - val_mae: 1.6889\n",
      "Epoch 23/50\n",
      "309/309 - 0s - loss: 5.1575 - mae: 1.6182 - val_loss: 5.2993 - val_mae: 1.6577\n",
      "Epoch 24/50\n",
      "309/309 - 0s - loss: 5.1755 - mae: 1.6160 - val_loss: 5.3507 - val_mae: 1.5883\n",
      "Epoch 25/50\n",
      "309/309 - 0s - loss: 5.1742 - mae: 1.6167 - val_loss: 5.2495 - val_mae: 1.6536\n",
      "Epoch 26/50\n",
      "309/309 - 0s - loss: 5.1474 - mae: 1.6153 - val_loss: 5.3135 - val_mae: 1.6788\n",
      "Epoch 27/50\n",
      "309/309 - 0s - loss: 5.1181 - mae: 1.6133 - val_loss: 5.2593 - val_mae: 1.6639\n",
      "Epoch 28/50\n",
      "309/309 - 0s - loss: 5.1527 - mae: 1.6146 - val_loss: 5.2724 - val_mae: 1.6399\n",
      "Epoch 29/50\n",
      "309/309 - 0s - loss: 5.1229 - mae: 1.6133 - val_loss: 5.2397 - val_mae: 1.6089\n",
      "Epoch 30/50\n",
      "309/309 - 0s - loss: 5.1228 - mae: 1.6018 - val_loss: 5.4180 - val_mae: 1.7623\n",
      "Epoch 31/50\n",
      "309/309 - 0s - loss: 5.1648 - mae: 1.6162 - val_loss: 5.3930 - val_mae: 1.7543\n",
      "Epoch 32/50\n",
      "309/309 - 0s - loss: 5.1131 - mae: 1.6055 - val_loss: 5.5888 - val_mae: 1.5738\n",
      "Epoch 33/50\n",
      "309/309 - 0s - loss: 5.1757 - mae: 1.6121 - val_loss: 5.2534 - val_mae: 1.6758\n",
      "Epoch 34/50\n",
      "309/309 - 0s - loss: 5.1068 - mae: 1.6071 - val_loss: 5.2200 - val_mae: 1.6389\n",
      "Epoch 35/50\n",
      "309/309 - 0s - loss: 5.1248 - mae: 1.6001 - val_loss: 5.1879 - val_mae: 1.6296\n",
      "Epoch 36/50\n",
      "309/309 - 0s - loss: 5.1199 - mae: 1.6071 - val_loss: 5.2003 - val_mae: 1.6437\n",
      "Epoch 37/50\n",
      "309/309 - 0s - loss: 5.0983 - mae: 1.5993 - val_loss: 5.4908 - val_mae: 1.8027\n",
      "Epoch 38/50\n",
      "309/309 - 0s - loss: 5.1354 - mae: 1.6065 - val_loss: 5.2909 - val_mae: 1.6722\n",
      "Epoch 39/50\n",
      "309/309 - 0s - loss: 5.1356 - mae: 1.6141 - val_loss: 5.4334 - val_mae: 1.7772\n",
      "Epoch 40/50\n",
      "309/309 - 0s - loss: 5.1570 - mae: 1.6050 - val_loss: 5.4054 - val_mae: 1.7750\n",
      "Epoch 41/50\n",
      "309/309 - 0s - loss: 5.0881 - mae: 1.6037 - val_loss: 5.3022 - val_mae: 1.7305\n",
      "Epoch 42/50\n",
      "309/309 - 0s - loss: 5.0744 - mae: 1.5928 - val_loss: 5.2498 - val_mae: 1.7009\n",
      "Epoch 43/50\n",
      "309/309 - 0s - loss: 5.0723 - mae: 1.5928 - val_loss: 5.2481 - val_mae: 1.5703\n",
      "Epoch 44/50\n",
      "309/309 - 0s - loss: 5.0569 - mae: 1.5951 - val_loss: 5.1649 - val_mae: 1.6269\n",
      "Epoch 45/50\n",
      "309/309 - 0s - loss: 5.0695 - mae: 1.5954 - val_loss: 5.2905 - val_mae: 1.7226\n",
      "Epoch 46/50\n",
      "309/309 - 0s - loss: 5.0383 - mae: 1.5945 - val_loss: 5.1666 - val_mae: 1.5922\n",
      "Epoch 47/50\n",
      "309/309 - 0s - loss: 5.0292 - mae: 1.5923 - val_loss: 5.1910 - val_mae: 1.5823\n",
      "Epoch 48/50\n",
      "309/309 - 0s - loss: 5.0644 - mae: 1.5980 - val_loss: 5.1694 - val_mae: 1.6017\n",
      "Epoch 49/50\n",
      "309/309 - 0s - loss: 5.0762 - mae: 1.5934 - val_loss: 5.1325 - val_mae: 1.5929\n",
      "Epoch 50/50\n",
      "309/309 - 0s - loss: 5.0597 - mae: 1.5891 - val_loss: 5.3060 - val_mae: 1.7426\n",
      "97/97 - 0s - loss: 5.0659 - mae: 1.6578\n",
      "-> Test dataset evaluation : Loss = 5.0659\n",
      "-> Test dataset evaluation : MAE = 1.6578\n"
     ]
    }
   ],
   "source": [
    "for train, test in skf.split(df_x, df_y): # skf로 셋팅된 환경에서 정의한 n_fold만큼 반복\n",
    "    print(\"=\"*14, \" training 데이터 개수 : \", len(train), \", test 데이터 개수 : \", len(test), \"=\"*14)\n",
    "    stage += 1\n",
    "    print(\"-> K = %d : %d 번째 그룹에 있는 test 데이터셋 사용 \" %(n_fold, stage))\n",
    "    \n",
    "    # 딥러닝 구조를 결정(모델을 설정), n_fold 번 반복됨\n",
    "    # 이전 딥러닝 모델1과 같은 구조로 설정하여 검증 방식에 따른 정확도 차이 비교를 하고자 한다. \n",
    "    model = Sequential()\n",
    "    #1번째 층 : 입력 x는 9개, 출력은 12개, 활성화함수 relu \n",
    "    model.add(Dense(12, input_dim=9, activation='relu'))\n",
    "    #2번째 층 : 입력 x는 12개, 출력은 9개, 활성화함수 relu \n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    #3번째 층 : 입력 x는 9개, 출력은 1개, 활성화함수 linear\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    # 모델 컴파일    \n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    \n",
    "    # 모델 실행\n",
    "    # 학습 데이터셋을 통한 학습: verbose가 2이면 함축적인 정보만 출력, epochs와 batch_sizes는 이전 모델과 동일하다.\n",
    "    model.fit(df_x[train], df_y[train], validation_data=(df_x[test],df_y[test]), epochs=50, batch_size=10, verbose=2)\n",
    "   \n",
    "    # 테스트 데이터셋을 통한 검증 \n",
    "    # 테스트 데이터셋 loss, mae(mae로 선형회귀 모델의 정확도 평가)\n",
    "    k_loss, k_mae = model.evaluate(x=df_x[train], y=df_y[train], verbose=2)    \n",
    "    # 테스트 데이터셋의 loss\n",
    "    print(\"-> Test dataset evaluation : Loss = {:.4f}\".format(k_loss))   \n",
    "    # 테스트 데이터셋의 MAE\n",
    "    print(\"-> Test dataset evaluation : MAE = {:.4f}\".format(k_mae))\n",
    "    \n",
    "    # save k_loss to loss list\n",
    "    loss.append(k_loss)\n",
    "    \n",
    "    # save k_mae to mae list\n",
    "    mae.append(k_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd914298",
   "metadata": {},
   "source": [
    "### 6. 딥러닝 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab43460",
   "metadata": {},
   "source": [
    "#### Loss(mse)를 K에 해당하는 횟수만큼 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "959e4dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K 값 :  5 \n",
      "Loss :  [5.035762310028076, 4.994692325592041, 5.117936611175537, 6.360251426696777, 5.065881729125977]\n"
     ]
    }
   ],
   "source": [
    "print(\"K 값 :  %.f \" % n_fold)\n",
    "print(\"Loss : \", loss) #loss 리스트 값 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7f2108",
   "metadata": {},
   "source": [
    "#### MAE를 K에 해당하는 횟수만큼 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baabf1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K 값 :  5 \n",
      "MAE :  [1.5784493684768677, 1.6452404260635376, 1.63773512840271, 1.6457065343856812, 1.6577982902526855]\n"
     ]
    }
   ],
   "source": [
    "print(\"K 값 :  %.f \" % n_fold)\n",
    "print(\"MAE : \", mae) # mae 리스트 값 출력 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eba516a",
   "metadata": {},
   "source": [
    "#### 테스트 데이터셋을 기반으로 K번 iteration이 적용된 MSE 및 MAE의 평균값 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8a16289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "\n",
      " MSE : 5.3149\n"
     ]
    }
   ],
   "source": [
    "# 리스트형을 넘파이에서 제공하는 배열로 변환 \n",
    "mse_ave = np.array(loss)\n",
    "print(type(mse_ave)) \n",
    "print(\"\\n MSE : %.4f\" %(mse_ave.mean()))  # mse 평균값 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef3e426c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "\n",
      " MAE : 1.6330\n"
     ]
    }
   ],
   "source": [
    "mae_ave = np.array(mae)\n",
    "print(type(mae_ave)) \n",
    "print(\"\\n MAE : %.4f\" %(mae_ave.mean()))  # mae 평균값 출력 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7944fe60",
   "metadata": {},
   "source": [
    "MAE 값이 1.6330가 나왔으므로 꽃게 나이 예측의 평균적인 오차값은 1.6330개월이라는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb1d2a4",
   "metadata": {},
   "source": [
    "### 7. 새로운 데이터를 위의 딥러닝 모델을 사용하여 예측하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5ef86d",
   "metadata": {},
   "source": [
    "keras의 Sequential 모델에서 제공하는 predict() 함수를 사용  \n",
    "아직 학습과 테스트에 사용하지 않은 데이터를 사용해 예측하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f08331ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crab1 나이 예측 : 11 개월\n",
      "crab2 나이 예측 : 8 개월\n"
     ]
    }
   ],
   "source": [
    "# Length, Diameter, Height, Weight, Viscera Weight, Shell Weight, Sex_F, Sex_I, Sex_M\n",
    "crab1 = np.array([[1.5305, 1.185, 0.4135, 24.7356155, 5.5858415, 6.749191, 1, 0, 0]])\n",
    "crab2 = np.array([[0.8975,0.67,0.2305,5.50050975,1.37645075,1.5602225,0,0,1]])\n",
    "\n",
    "test_crab1 = model.predict(crab1)\n",
    "test_crab2 = model.predict(crab2)\n",
    "\n",
    "print(\"crab1 나이 예측 : %.f\" %test_crab1, \"개월\")\n",
    "print(\"crab2 나이 예측 : %.f\" %test_crab2, \"개월\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c5e82e",
   "metadata": {},
   "source": [
    "실제 데이터를 바탕으로 만든 가상의 꽃게 데이터에서 딥러닝 모델이 꽤 정확하게 동작함을 확인할 수 있었다.  \n",
    "crab1은 데이터 셋의 첫 번째 crab 데이터의 각 독립변수들을 조금씩 증가시켜 생후 11개월 정도의 crab을 만들었고, crab2는 데이터 셋의 두 번째 crab 데이터의 각 독립변수들을 조금씩 증가시켜 생후 8개월 정도의 crab을 만든 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a58d902",
   "metadata": {},
   "source": [
    "### 8. 학습 모델 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0cf1f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('CrabAge3.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f712ff",
   "metadata": {},
   "source": [
    "### 9. 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a4aa84",
   "metadata": {},
   "source": [
    "이전의 모델들과 마찬가지로 꽃게 나이 예측의 평균적인 오차값이 1.6330개월인 것은 예측이 잘 되었다고 생각한다. 그러나 처음 만든 홀드 아웃 교차 검증을 사용한 딥러닝 모델 1(오차: 1.5869개월)에 비해서 오차값이 크고, K겹 교차 검증 방식 자체가 시간이 상당히 오래 걸리는 검증 방식이기 때문에 비효율적이라고 생각한다. 또한 똑같은 K겹 교차 검증 방식을 사용한 모델 2(오차: 1.6262개월)와 비교해 보았을 때도 오차가 더 크게 나타났다. 나는 EarlyStopping() 함수가 오차를 크게 만드는데 기여하였다고 생각했는데 그것이 아니었다. 확실히 mae 리스트의 4번째 값은 EarlyStopping()를 사용하지 않아서 줄어들었지만, 다른 원소들의 오차값이 증가하여 MAE의 평균이 상승하는 효과를 불러일으켰다. 이를 통해 EarlyStopping() 함수는 오차를 줄이는데 효과적임을 확인할 수 있었다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2c07e6",
   "metadata": {},
   "source": [
    "그렇다면, K겹 교차 검증 방식이 홀드 아웃 교차 검증보다 더 큰 오차를 보이는 이유는 무엇일까? 과적합이 일어나지 않을 정도로 큰 테스트 데이터셋을 확보할 수 있으면 홀드 아웃 교차 검증의 성능이 더 좋은 것일까? 나는 학습 데이터셋과 테스트 데이터셋이 충분히 크고 데이터가 편향없이 고르게 분포되었기 때문에 30%의 테스트 데이터 셋을 확보한 홀드 아웃 교차 검증이 20%의 테스트 데이터 셋을 사용한 K겹 교차 검증 방식(이때 K=5)보다 우수한 성능을 보이는 일이 발생하였다고 생각한다. 여기에서 나는 K겹 교차 검증 방식의 개선 방안으로 iteration 마다 나오는 성능 평가 지표의 평균을 구하는 것이 아니라 중앙값을 구하는 방식을 생각하였다. 그렇게 된다면 본 모델과 이전의 딥러닝 모델 2의 경우에 K겹 교차 검증 방식의 오차는 더 줄어들게 된다. 특히 이전의 딥러닝 모델 2는 오차가 1.5885개월이 되어 딥러닝 모델1과 비슷한 정확도를 보여준다. 또는 데이터셋이 충분히 큰 위와 같은 경우에는 K = 3로 설정하여 3겹 교차 검증 방식을 사용한다면 33.3%가 테스트 데이터로 사용되기 때문에 더 좋은 성능을 보여줄 것이라 생각한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f4edd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
